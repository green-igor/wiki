{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install imbalanced-learn -q\n",
    "#!pip install swifter - q\n",
    "\n",
    "#!pip install lightgbm\n",
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import notebook\n",
    "import re\n",
    "from time import time \n",
    "#import nltk\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from __future__ import unicode_literals, print_function\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spacy\n",
    "#from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "#from spacy.pipeline import Lemmatizer\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = transformers.BertTokenizer(\n",
    "#    vocab_file='datasets/ds_bert/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x1ce325ca190>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = English()\n",
    "nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2002, 2743, 1012, 2002, 3062, 1012, 102]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('He ran. He fell.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[PAD]': 0, '[UNK]': 100, '[CLS]': 101, '[SEP]': 102, '[MASK]': 103}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.added_tokens_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, '[CLS]')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2002, 'he')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2743, 'ran')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1012, '.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2002, 'he')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3062, 'fell')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1012, '.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(13360, 'aaa')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(11057, '##aa')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(11057, '##aa')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(11057, '##aa')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(11057, '##aa')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1012, '.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1012, '.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1012, '.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(102, '[SEP]')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for enc in tokenizer.encode('He ran. He fell. Aaaaaaaaaaa...'):\n",
    "    display((enc,tokenizer.decode([f'{enc}'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "#df['text'].apply(lambda x: len(str(x).split()))\n",
    "end = time()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://code.s3.yandex.net/datasets/toxic_comments.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    string = re.sub(r'[^a-z]', ' ', string, flags=re.IGNORECASE)\n",
    "    string = string.split()\n",
    "    string = ' '.join(string)\n",
    "    return string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].apply(lambda x:clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1323"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='clean_text', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.lower().duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text          0\n",
       "toxic         0\n",
       "clean_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sents(string):\n",
    "    doc = nlp(string)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['text'].apply(lambda x: x.count(' ') + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['sent_count'] = df['text'].apply(lambda x: len(sents(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['len'] = df['text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Turret #4\\n\\nWhy did the builder raise turret #4 on a high mount, while #3 sits on a normal low mount? It can only fire broadside, so why bother with added top weight? East of Borschov'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][154485]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df['text'][112719]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 157969 entries, 0 to 157968\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   text        157969 non-null  object\n",
      " 1   toxic       157969 non-null  int64 \n",
      " 2   clean_text  157969 non-null  object\n",
      " 3   word_count  157969 non-null  int64 \n",
      " 4   len         157969 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['text_lower'] = df['mid_text'].str.lower()\n",
    "#df.drop_duplicates(subset='text_lower', inplace=True)\n",
    "#df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_plt(df_list, name, val_list, plt_xlim=1):\n",
    "\n",
    "    x_max = min([series.max() for series in df_list])* plt_xlim\n",
    "\n",
    "    fig, ax = plt.subplots(2,1,figsize=(10,8))\n",
    "    ax[0].boxplot([df for df in df_list], vert=False)\n",
    "\n",
    "    ax[0].set_yticklabels(val_list)\n",
    "    ax[0].set_xlabel(name)\n",
    "    ax[0].set_xlim([0, x_max])\n",
    "\n",
    "    ax[1].hist([df for df in df_list], histtype='stepfilled', bins=500)\n",
    "    ax[1].set_ylabel('частота')\n",
    "    ax[1].set_xlabel(name)\n",
    "    ax[1].set_xlim([0, x_max])\n",
    "\n",
    "    \n",
    "    plt.suptitle(f'Ящики с усами и гистограмма для признака \"{name}\"')\n",
    "    plt.legend(val_list);\n",
    "    #plt.xlim((0,x_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict = {'word_count' : 'количество слов',\n",
    " 'sent_count' : 'количество предложений',\n",
    " 'len' : 'количество символов'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for col in ['word_count', 'sent_count', 'len']:\n",
    "    \n",
    "    distribution_plt(\n",
    "        \n",
    "        [df[df['toxic']==1][col], df[df['toxic']==0][col]],\n",
    "        \n",
    "        name_dict[col],\n",
    "        \n",
    "        ['токсичные\\nкомментарии', 'не токсичные\\nкомментарии'],\n",
    "        \n",
    "        0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_rebuild(word_list):\n",
    "    \n",
    "    for word in range(len(word_list)):\n",
    "        if len(word_list[word])>100:\n",
    "            word_list[word] = ''.join(list(dict.fromkeys(word_list[word])))\n",
    "    \n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = transformers.BertConfig.from_dict({\n",
    "      \"attention_probs_dropout_prob\": 0.1,\n",
    "      \"directionality\": \"bidi\",\n",
    "      \"hidden_act\": \"gelu\",\n",
    "      \"hidden_dropout_prob\": 0.1,\n",
    "      \"hidden_size\": 768,\n",
    "      \"initializer_range\": 0.02,\n",
    "      \"intermediate_size\": 3072,\n",
    "      #\"layer_norm_eps\": 7e-2,\n",
    "      \"layer_norm_eps\": 1e-12,\n",
    "      #\"layer_norm_eps\": 4e-5,\n",
    "      \"max_position_embeddings\": 512,\n",
    "      \"model_type\": \"bert\",\n",
    "      \"num_attention_heads\": 12,\n",
    "      \"num_hidden_layers\": 12,\n",
    "      \"pad_token_id\": 0,\n",
    "      \"pooler_fc_size\": 768,\n",
    "      \"pooler_num_attention_heads\": 12,\n",
    "      \"pooler_num_fc_layers\": 3,\n",
    "      \"pooler_size_per_head\": 128,\n",
    "      \"pooler_type\": \"first_token_transform\",\n",
    "      #\"position_embedding_type\": \"absolute\",\n",
    "      #\"transformers_version\": \"4.12.5\",\n",
    "      \"use_cache\":True,\n",
    "      \"type_vocab_size\": 2,\n",
    "      \"vocab_size\": 30522\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.56.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def chunker(string, max_tokens):\n",
    "\n",
    "    sents_ = sents(string)\n",
    "\n",
    "    tokenized_sents = [tokenizer.encode(sent, add_special_tokens=True) for sent in sents_]\n",
    "    \n",
    "    toks=[]\n",
    "    \n",
    "    for token in tokenized_sents:\n",
    "        if token not in toks:\n",
    "            toks.append(token)\n",
    "    \n",
    "    if len(toks)>1:\n",
    "        result = sum(toks,[])    \n",
    "    else:\n",
    "        result = toks[0]\n",
    "    \n",
    "    if len(result)>max_tokens:\n",
    "        \n",
    "        mid_sent = len(toks)//2\n",
    "        \n",
    "        if mid_sent == 1:\n",
    "            \n",
    "            if len(toks[1])<max_tokens:\n",
    "                result = toks[1]    \n",
    "            else:\n",
    "                result = toks[0]\n",
    "                \n",
    "        elif mid_sent > 1:\n",
    "            \n",
    "            for s in range(1,mid_sent):\n",
    "\n",
    "                mid_sents = toks[(mid_sent-s):mid_sent] + toks[mid_sent:(mid_sent+s)]#+toks[-1]\n",
    "                mid_sents_s = sum(mid_sents,[])\n",
    "                if len(mid_sents_s) > max_tokens:\n",
    "                    break\n",
    "                    result = sum(mid_sents[:-1],[])\n",
    "        \n",
    "        else:\n",
    "            result = sum(toks,[])\n",
    "    #return result\n",
    "    return result[:max_tokens][:-1]+[102]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def chunker(string, max_tokens):\n",
    "\n",
    "    max_tokens = max_tokens-1\n",
    "    sents_ = sents(string)\n",
    "\n",
    "    \n",
    "    tokenized_sents = [tokenizer.encode(sent, add_special_tokens=False) for sent in sents_]\n",
    "    \n",
    "    toks=[]\n",
    "    \n",
    "    for token in tokenized_sents:\n",
    "        if token not in toks:\n",
    "            toks.append(token)\n",
    "    \n",
    "\n",
    "    result = sum(toks,[])    \n",
    "    \n",
    "    if len(result)>max_tokens:\n",
    "        if len(sents_)>2:\n",
    "            result = toks[0]+toks[-1]\n",
    "    \n",
    "            \n",
    "    return [101] + result[:max_tokens-2] + [102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def chunker(string, max_tokens=512):\n",
    "    sents_ = sents(string)\n",
    "    \n",
    "    tokenized_sents = [tokenizer.encode(sent, add_special_tokens=False) for sent in sents_]\n",
    "    \n",
    "    toks=[]\n",
    "    \n",
    "    for token in tokenized_sents:\n",
    "        if token not in toks:\n",
    "            toks.append(token)\n",
    "        \n",
    "    result = sum(toks, [])#[:-1]\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(string, max_tokens=512):\n",
    "\n",
    "    tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    tokenized = tokenizer.encode(string, add_special_tokens=True)\n",
    "\n",
    "    result = tokenized[:max_tokens]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def chunker(string, max_tokens=512):\n",
    "\n",
    "    sents_ = sents(string)\n",
    "\n",
    "    tokenized_sents = [tokenizer.encode(sent, add_special_tokens=True) for sent in sents_]\n",
    "    \n",
    "    toks=[]\n",
    "    \n",
    "    for token in tokenized_sents:\n",
    "        if token not in toks:\n",
    "            toks.append(token)\n",
    "    result = sum(toks, [])#[:-1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(set(result))>len(result)*0.7:\n",
    "  \n",
    "        result = list(dict.fromkeys(result))[:-1]\n",
    "    \n",
    "    \n",
    "    result = result[:max_tokens-1]\n",
    "    \n",
    "    if result[-1]!=102:\n",
    "        result = result[:max_tokens-1] + [102]\n",
    "\n",
    "    \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dab said:\\n\\nMy impression remainst that the only reason this article is so long and detailed is the attempt to disguise from the casual reader the fact that the entire thing can be shrugged off in a one-liner.\\n\\nYes, that's probably true, but what is the alternative?  Many of us have been battling to make the CMT clear, but every time a statement is made on how crazy the theory is, the other side asks for a proof/citation.  And since that has happened almost every week for the last six months (and probably longer), the article has grown in size.  I'm not sure how we can overcome this problem, but I'm open to suggestions.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][4704]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] dab said : my impression remainst that the only reason this article is so long and detailed is the attempt to disguise from the casual reader the fact that the entire thing can be shrugged off in a one - liner. yes, that's probably true, but what is the alternative? many of us have been battling to make the cmt clear, but every time a statement is made on how crazy the theory is, the other side asks for a proof / citation. and since that has happened almost every week for the last six months ( and probably longer ), the article has grown in size. i'm not sure how we can overcome this problem, but i'm open to suggestions. [SEP]\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(chunker(df['text'][4704]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] dab said : my impression remainst that the only reason this article is so long and detailed is the attempt to disguise from the casual reader the fact that the entire thing can be shrugged off in a one - liner. yes, that's probably true, but what is the alternative? many of us have been battling to make the cmt clear, but every time a statement is made on how crazy the theory is, the other side asks for a proof / citation. and since that has happened almost every week for the last six months ( and probably longer ), the article has grown in size. i'm not sure how we can overcome this problem, but i'm open to suggestions. [SEP]\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(df['text'][4704]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4700    do go fuck off bastard\\nDo Yyou Have a life?\\n...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'].str.contains('I ass. I ass.')]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2092 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] do go fuck off bastard do yyou have a life? go fuck off bastard and yank your cock through your ass. i hate you and hope you go away forever. lame is you fuck your mom. die die die and all that crap. this is for mahy mahonerz ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass. i ass'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(chunker(df['text'][4700], 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df[df['text'].apply(lambda x: len(x))>=4900]['text'].apply(lambda x: len(chunker(x))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] : file : jamaican railroad with railcar and station 1960. jpg hi, i found the above photo but i have no idea what railcar is shown where on jamaica. maybe you can help? cheers [SEP]'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(chunker(df['text'][82496]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128381    \"David on a personal note - you are an erudite...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2053, 1010, 2009, 2965, 2008, 2002, 1005, 1055, 2019]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(2)['text'].apply(lambda x: chunker(x,10)).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df['text'][82496]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['text'][116571]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def chunker(string, max_tokens=512):\n",
    "\n",
    "\n",
    "    \n",
    "    tokenized = tokenizer.encode(string, add_special_tokens=False)\n",
    "    len_wo_tokens = max_tokens-2\n",
    "    \n",
    "    if len(tokenized)> len_wo_tokens:\n",
    "        \n",
    "        result = tokenized[:(len_wo_tokens//2)] + tokenized[::-1][:(len_wo_tokens//2)][::-1]\n",
    "    else:\n",
    "        result = tokenized\n",
    "\n",
    "    return [101] + result + [102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#chunker(df['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OSError: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
    "#Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_batch = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init_config = config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenized = X_train.swifter.apply(lambda x: chunker(x,max_batch))\n",
    "#tokenized = text.apply(lambda x: chunker(x,max_batch))\n",
    "\n",
    "max_len = 0\n",
    "\n",
    "for tok in tokenized.values:\n",
    "    if len(tok) > max_len:\n",
    "        max_len = len(tok)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "\n",
    "\n",
    "model = transformers.BertModel.from_pretrained('bert-base-uncased', config=init_config)\n",
    "#model.config.max_position_embeddings = max_batch\n",
    "\n",
    "\n",
    "batch_size = batch_size\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "\n",
    "train_features = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_tokenized = X_test.swifter.apply(lambda x: chunker(x,max_batch))\n",
    "\n",
    "\n",
    "max_len = 0\n",
    "for tok in test_tokenized.values:\n",
    "    if len(tok) > max_len:\n",
    "        max_len = len(tok)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in test_tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "\n",
    "test_embeddings = []\n",
    "\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        test_embeddings.append(test_batch_embeddings[0][:,0,:].numpy())\n",
    "\n",
    "test_features = np.concatenate(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bert_emb(object):\n",
    "\n",
    "\n",
    "    def __init__(self, data, init_config,  batch_size=32, max_batch=512):\n",
    "\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.max_batch = max_batch\n",
    "        self.init_config = init_config \n",
    "\n",
    "        #self.config.max_position_embeddings = max_batch\n",
    "        self.model = transformers.BertModel.from_pretrained('bert-base-uncased', config=init_config)\n",
    "    \n",
    "    def embedder(self):\n",
    "\n",
    "        tokenized = self.data.swifter.apply(lambda x: chunker(x, self.max_batch))\n",
    "        #tokenized = self.data.apply(lambda x:list(tokenizer(x,add_special_tokens=True)))#.iloc[:self.max_batch]\n",
    "        #tokenized = self.data.apply(lambda x: tokenizer(x,add_special_tokens=True))\n",
    "        #tokenized = tokenized.values.tolist()\n",
    "        \n",
    "        max_len = 0\n",
    "        \n",
    "        for tok in tokenized.values:\n",
    "            if len(tok) > max_len:\n",
    "                max_len = len(tok)\n",
    "    \n",
    "        #padded = [i + [0]*(max_len - len(i)) for i in tokenized.values]\n",
    "        padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])#,dtype=np.int64)\n",
    "        attention_mask = np.where(padded != 0, 1, 0)\n",
    "        \n",
    "        batch_size = self.batch_size\n",
    "        \n",
    "        embeddings = []\n",
    "        \n",
    "        for i in notebook.tqdm(range(len(padded) // batch_size)):\n",
    "                batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "                attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    batch_embeddings = self.model(batch, attention_mask=attention_mask_batch)\n",
    "                \n",
    "                embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "    \n",
    "        features = np.concatenate(embeddings)\n",
    "\n",
    "        return features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert_emb(df['text'][0:5],config,1).embedder().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logy(feats, target):\n",
    "    lr = LogisticRegression(random_state=RANDOM_STATE,max_iter=feats.shape[1],class_weight='balanced')\n",
    "    lr.fit(feats, target)\n",
    "    scores = cross_val_score(lr, feats, target, cv=5, scoring='f1_macro')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df[df['len']<=df['len'].quantile(0.9)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = df.sample(frac=0.5, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test = df[df.index.isin(df_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.shape,df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len_q_upper = df_train['len'].quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len_q_lower = df_train['len'].quantile(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_train = df_train[(df_train['len'] >= len_q_lower) & (df_train['len'] <= len_q_upper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_for_test1 = df[df['toxic']==1].sample(n=512,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_for_test = df[df['toxic']==0].sample(n=512,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_for_test = pd.concat([df_for_test,df_for_test1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train=df_for_test['text']\n",
    "y_train = df_for_test['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_test = df[~df.index.isin(X_test.index)].sample(n=1024,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "y_test = X_test['toxic']\n",
    "X_test = X_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#bert_emb(df['text'][0:1],config,batch_size=1,max_batch=10).embedder()[0]==bert_emb(df['text'][0:5],config,batch_size=1,max_batch=10).embedder()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8192"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best - 32768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157969, 5)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = df.sample(n=32768, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in samp.iloc[:,2:-1]:\n",
    "#    display(i, samp[i].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'],\n",
    "    df['toxic'],\n",
    "    test_size = 0.50,\n",
    "    random_state = RANDOM_STATE,\n",
    "    stratify = df['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    samp['text'],\n",
    "    samp['toxic'],\n",
    "    test_size = 0.50,\n",
    "    random_state = RANDOM_STATE,\n",
    "    stratify = samp['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'],\n",
    "    df['toxic'],\n",
    "    test_size = 0.50,\n",
    "    random_state = RANDOM_STATE,\n",
    "    stratify = df['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78984,), (78985,), (78984,), (78985,))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = RandomUnderSampler(random_state=RANDOM_STATE)\n",
    "X_resample, y_resample = sampler.fit_resample(pd.DataFrame(X_train), pd.DataFrame(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16048, 1), (16048, 1))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resample.shape, y_resample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                     text\n",
       " 29597                              look better than that.\n",
       " 52827                                So far so good 8^) -\n",
       " 107079           Similarities between IVC and VEDIC TIMES\n",
       " 75356   I should point out to you that User:MikeMcGD d...\n",
       " 147762  \" I have also provided a few more arguments in...,\n",
       "         toxic\n",
       " 29597       0\n",
       " 52827       0\n",
       " 107079      0\n",
       " 75356       0\n",
       " 147762      0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resample.head(), y_resample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                     text\n",
       " 118039  \"\\n\\nCool, you proposed the deletion of \"\"Sant...\n",
       " 10015              go suck a dick \\n\\nplease 71.178.201.4\n",
       " 132276                 Yup \\n\\nGo fuck yourself. — lfdder\n",
       " 21028              cheers \\ndie in a fire, fianna failure\n",
       " 70621   Pay attention dipshit, there is consensus, to ...,\n",
       "         toxic\n",
       " 118039      1\n",
       " 10015       1\n",
       " 132276      1\n",
       " 21028       1\n",
       " 70621       1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resample.tail(), y_resample.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16048, 1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "config = transformers.BertConfig.from_dict({\n",
    "      \"attention_probs_dropout_prob\": 0.1,\n",
    "      \"directionality\": \"bidi\",\n",
    "      \"hidden_act\": \"gelu\",\n",
    "      \"hidden_dropout_prob\": 0.1,\n",
    "      \"hidden_size\": 768,\n",
    "      \"initializer_range\": 0.02,\n",
    "      \"intermediate_size\": 3072,\n",
    "      \"layer_norm_eps\": 1e-12,\n",
    "      \"max_position_embeddings\": 512,\n",
    "      \"model_type\": \"bert\",\n",
    "      \"num_attention_heads\": 12,\n",
    "      \"num_hidden_layers\": 12,\n",
    "      \"pad_token_id\": 0,\n",
    "      \"pooler_fc_size\": 768,\n",
    "      \"pooler_num_attention_heads\": 12,\n",
    "      \"pooler_num_fc_layers\": 3,\n",
    "      \"pooler_size_per_head\": 128,\n",
    "      \"pooler_type\": \"first_token_transform\",\n",
    "      \"type_vocab_size\": 2,\n",
    "      \"vocab_size\": 30522\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16048"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resample.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "X_resample = X_resample['text'].sort_index()\n",
    "y_resample = y_resample['toxic'].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                     text\n",
       " 29597                              look better than that.\n",
       " 52827                                So far so good 8^) -\n",
       " 107079           Similarities between IVC and VEDIC TIMES\n",
       " 75356   I should point out to you that User:MikeMcGD d...\n",
       " 147762  \" I have also provided a few more arguments in...,\n",
       "                                                      text\n",
       " 118039  \"\\n\\nCool, you proposed the deletion of \"\"Sant...\n",
       " 10015              go suck a dick \\n\\nplease 71.178.201.4\n",
       " 132276                 Yup \\n\\nGo fuck yourself. — lfdder\n",
       " 21028              cheers \\ndie in a fire, fianna failure\n",
       " 70621   Pay attention dipshit, there is consensus, to ...)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resample.head(), X_resample.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        toxic\n",
       " 29597       0\n",
       " 52827       0\n",
       " 107079      0\n",
       " 75356       0\n",
       " 147762      0,\n",
       "         toxic\n",
       " 118039      1\n",
       " 10015       1\n",
       " 132276      1\n",
       " 21028       1\n",
       " 70621       1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resample.head(), y_resample.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16048, 1)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "778/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class BertTokenizer(object):\n",
    "\n",
    "    def __init__(self, text=[]):\n",
    "        self.text = text\n",
    "\n",
    "        # For DistilBERT:\n",
    "        self.model_class, self.tokenizer_class, self.pretrained_weights = (transformers.DistilBertModel, transformers.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "        # Load pretrained model/tokenizer\n",
    "        self.tokenizer = self.tokenizer_class.from_pretrained(self.pretrained_weights)\n",
    "\n",
    "        self.model = self.model_class.from_pretrained(self.pretrained_weights)\n",
    "\n",
    "    def get(self):\n",
    "\n",
    "        df = pd.DataFrame(data={\"text\":self.text})\n",
    "        tokenized = df[\"text\"].swifter.apply((lambda x: self.tokenizer.encode(x, add_special_tokens=True)[:512]))\n",
    "\n",
    "        max_len = 0\n",
    "        for i in tokenized.values:\n",
    "            if len(i) > max_len:\n",
    "                max_len = len(i)\n",
    "\n",
    "        padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "\n",
    "        attention_mask = np.where(padded != 0, 1, 0)\n",
    "        input_ids = torch.tensor(padded)\n",
    "        attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "        with torch.no_grad(): last_hidden_states = self.model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        features = last_hidden_states[0][:, 0, :].numpy()\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTokenizer(object):\n",
    "\n",
    "    def __init__(self, text=[], batch_size=32):\n",
    "        self.text = text\n",
    "        self.batch_size = batch_size\n",
    "        # For DistilBERT:\n",
    "        self.model_class, self.tokenizer_class, self.pretrained_weights = (transformers.BertModel, transformers.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "        # Load pretrained model/tokenizer\n",
    "        self.tokenizer = self.tokenizer_class.from_pretrained(self.pretrained_weights)\n",
    "\n",
    "        self.model = self.model_class.from_pretrained(self.pretrained_weights)\n",
    "\n",
    "    def get(self):\n",
    "\n",
    "        df = pd.DataFrame(data={\"text\":self.text})\n",
    "        tokenized = df[\"text\"].swifter.apply((lambda x: self.tokenizer.encode(x, add_special_tokens=True)[:512]))\n",
    "\n",
    "        max_len = 0\n",
    "        \n",
    "        for tok in tokenized.values:\n",
    "            if len(tok) > max_len:\n",
    "                max_len = len(tok)\n",
    "    \n",
    "        #padded = [i + [0]*(max_len - len(i)) for i in tokenized.values]\n",
    "        padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])#,dtype=np.int64)\n",
    "        attention_mask = np.where(padded != 0, 1, 0)\n",
    "        \n",
    "        batch_size = self.batch_size\n",
    "        \n",
    "        embeddings = []\n",
    "        \n",
    "        for i in notebook.tqdm(range(len(padded) // batch_size)):\n",
    "                batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "                attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    batch_embeddings = self.model(batch, attention_mask=attention_mask_batch)\n",
    "                \n",
    "                embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "    \n",
    "        features = np.concatenate(embeddings)\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250.75"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resample.shape[0]/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023115fc848845e8adaada8ba831ff25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/16000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9c431eb7074e5d8e023355903e0214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dembs = BertTokenizer(text=X_resample['text'].iloc[:16000], batch_size=200).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88374886, 0.89092292, 0.89216221, 0.89125   , 0.88062425])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logy(dembs, y_resample['toxic'].iloc[:16000])#.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.850558174"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0.85350318, 0.8625    , 0.87179487, 0.82352941, 0.84146341]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134385    I struggle to see the very tenuous link betwee...\n",
       " 7758      Copyright Superstar!!  wow supergreat star!!! ...\n",
       " 132071    \"Since my other attempts have failed to get th...\n",
       " 120297    read it here  GMC- Expediency before Principle...\n",
       " 3868                         \"\\n\\n Spam \\n\\n contribstalk \"\n",
       " Name: text, dtype: object,\n",
       " 134385    0\n",
       " 7758      0\n",
       " 132071    0\n",
       " 120297    0\n",
       " 3868      0\n",
       " Name: toxic, dtype: int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(), y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = pd.DataFrame(X_test).join(pd.DataFrame(y_test)).sample(n=dembs.shape[0], random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27250</th>\n",
       "      <td>\"\\n\\nP.S. In response to 'canvassing': I think...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49733</th>\n",
       "      <td>Wow. Thanks. Pretty crap reason for deleting i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18611</th>\n",
       "      <td>\"\\nThank you, Sir. I greatly appreciate your r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71920</th>\n",
       "      <td>please dont waste your time on me ,  dont you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5261</th>\n",
       "      <td>What does copyright mean when we are talking o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  toxic\n",
       "27250  \"\\n\\nP.S. In response to 'canvassing': I think...      0\n",
       "49733  Wow. Thanks. Pretty crap reason for deleting i...      0\n",
       "18611  \"\\nThank you, Sir. I greatly appreciate your r...      0\n",
       "71920  please dont waste your time on me ,  dont you ...      1\n",
       "5261   What does copyright mean when we are talking o...      0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array([0.88311688, 0.88303797, 0.76315789, 0.82868042, 0.82820379])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd66d600449465f89646e9806c58a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/16000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4af8535dc32477c952a4c3a23161e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dembs_test = BertTokenizer(text=test_sample['text'].iloc[:16000], batch_size=200).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    0.89841\n",
       "1    0.10159\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_eval(y_true, y_pred,):\n",
    "    #y_true = dtrain.get_label()\n",
    "    #err = 1 - f1_score(grid_pred, y_test, average=None)[1]\n",
    "    err = f1_score(y_pred, y_true, average=None)[1]\n",
    "    return  err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_xgb(y_pred, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    err = f1_score(y_true, y_pred, average=None)[1]\n",
    "\n",
    "    return 'err', err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "my_func = make_scorer(f1_eval, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "\n",
    "    {\n",
    "        'models': [LogisticRegression(\n",
    "            random_state=RANDOM_STATE, class_weight='balanced')],\n",
    "        'models__solver': ['newton-cg', 'liblinear'],\n",
    "        #'models__class_weight':,\n",
    "        'models__C': [0.1, 1]#,\n",
    "        #'models__penalty': ['l1', 'l2']\n",
    "          \n",
    "    },\n",
    "\n",
    "    {\n",
    "        'models': [SVC(random_state=RANDOM_STATE, class_weight='balanced')],\n",
    "        'models__degree': range(3,8),\n",
    "        'models__kernel': ['poly','rbf','sigmoid']\n",
    "    },\n",
    "    {\n",
    "        'models': [XGBClassifier(random_state=RANDOM_STATE, maximize=True)],\n",
    "        'models__n_estimators':[500],\n",
    "        'models__learning_rate':[0.1, 0.07, 0.05],\n",
    "        'models__eval_metric': [f1_xgb]\n",
    "    }\n",
    "    #{\n",
    "    #    'models': [LGBMClassifier(random_state=RANDOM_STATE, class_weight='balanced')],\n",
    "    #    'models__n_estimators': [1000],\n",
    "    #    'models__learning_rate': [0.1, 0.01, 0.03, 0.05, 0.07]\n",
    "    #}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param_grid = [\n",
    "\n",
    "    {\n",
    "        'models': [LogisticRegression(\n",
    "            random_state=RANDOM_STATE, class_weight='balanced')],\n",
    "        'models__solver': ['newton-cg', 'liblinear'],\n",
    "        #'models__class_weight':,\n",
    "        'models__C': [0.1, 1]#,\n",
    "        #'models__penalty': ['l1', 'l2']\n",
    "          \n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('models', LogisticRegression(\n",
    "            random_state=RANDOM_STATE))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;models&#x27;,\n",
       "                                        LogisticRegression(random_state=88))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;models&#x27;: [LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                        random_state=88)],\n",
       "                          &#x27;models__C&#x27;: [0.1, 1],\n",
       "                          &#x27;models__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;liblinear&#x27;]},\n",
       "                         {&#x27;models&#x27;: [SVC(class_weight=&#x27;balanced&#x27;,\n",
       "                                         random_state=88)],\n",
       "                          &#x27;models__degree&#x27;: range(3, 8),\n",
       "                          &#x27;models__kern...\n",
       "                                                   max_delta_step=None,\n",
       "                                                   max_depth=None,\n",
       "                                                   max_leaves=None,\n",
       "                                                   maximize=True,\n",
       "                                                   min_child_weight=None,\n",
       "                                                   missing=nan,\n",
       "                                                   monotone_constraints=None,\n",
       "                                                   multi_strategy=None,\n",
       "                                                   n_estimators=None,\n",
       "                                                   n_jobs=None, ...)],\n",
       "                          &#x27;models__eval_metric&#x27;: [&lt;function f1_xgb at 0x000001CE586CA2A0&gt;],\n",
       "                          &#x27;models__learning_rate&#x27;: [0.1, 0.07, 0.05],\n",
       "                          &#x27;models__n_estimators&#x27;: [500]}],\n",
       "             scoring=make_scorer(f1_eval, response_method=&#x27;predict&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">Pipeline(step...m_state=88))])</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">param_grid&nbsp;</td>\n",
       "            <td class=\"value\">[{&#x27;models&#x27;: [LogisticRegre...ndom_state=88)], &#x27;models__C&#x27;: [0.1, 1], &#x27;models__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;liblinear&#x27;]}, {&#x27;models&#x27;: [SVC(class_wei...ndom_state=88)], &#x27;models__degree&#x27;: range(3, 8), &#x27;models__kernel&#x27;: [&#x27;poly&#x27;, &#x27;rbf&#x27;, ...]}, ...]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scoring&nbsp;</td>\n",
       "            <td class=\"value\">make_scorer(f...hod=&#x27;predict&#x27;)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">refit&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cv&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">pre_dispatch&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">error_score&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">return_train_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___models__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('kernel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">kernel&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;poly&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('degree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">degree&nbsp;</td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;scale&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('coef0',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">coef0&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('shrinking',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">shrinking&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('probability',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">probability&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cache_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cache_size&nbsp;</td>\n",
       "            <td class=\"value\">200</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decision_function_shape',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">decision_function_shape&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;ovr&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('break_ties',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">break_ties&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">88</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('models',\n",
       "                                        LogisticRegression(random_state=88))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'models': [LogisticRegression(class_weight='balanced',\n",
       "                                                        random_state=88)],\n",
       "                          'models__C': [0.1, 1],\n",
       "                          'models__solver': ['newton-cg', 'liblinear']},\n",
       "                         {'models': [SVC(class_weight='balanced',\n",
       "                                         random_state=88)],\n",
       "                          'models__degree': range(3, 8),\n",
       "                          'models__kern...\n",
       "                                                   max_delta_step=None,\n",
       "                                                   max_depth=None,\n",
       "                                                   max_leaves=None,\n",
       "                                                   maximize=True,\n",
       "                                                   min_child_weight=None,\n",
       "                                                   missing=nan,\n",
       "                                                   monotone_constraints=None,\n",
       "                                                   multi_strategy=None,\n",
       "                                                   n_estimators=None,\n",
       "                                                   n_jobs=None, ...)],\n",
       "                          'models__eval_metric': [<function f1_xgb at 0x000001CE586CA2A0>],\n",
       "                          'models__learning_rate': [0.1, 0.07, 0.05],\n",
       "                          'models__n_estimators': [500]}],\n",
       "             scoring=make_scorer(f1_eval, response_method='predict'))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    pipe, \n",
    "    param_grid, \n",
    "    cv=10,\n",
    "    #scoring='f1',\n",
    "    scoring=my_func,\n",
    "    \n",
    "    n_jobs=-1\n",
    ")\n",
    "#grid_search.fit(X_resample[:X_test.shape[0]], y_resample['toxic'][:X_test.shape[0]])\n",
    "\n",
    "#grid_search.fit(embs, y_resample['toxic'].iloc[:test_sample.shape[0]])\n",
    "#grid_search.fit(embs, y_resample)\n",
    "#grid_search.fit(embs, y_train)\n",
    "grid_search.fit(dembs, y_resample['toxic'].values[:16000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.891811</td>\n",
       "      <td>{'models': SVC(class_weight='balanced', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0.891584</td>\n",
       "      <td>{'models': SVC(class_weight='balanced', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>0.891361</td>\n",
       "      <td>{'models': SVC(class_weight='balanced', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>0.890961</td>\n",
       "      <td>{'models': SVC(class_weight='balanced', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>0.890961</td>\n",
       "      <td>{'models': SVC(class_weight='balanced', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0.890961</td>\n",
       "      <td>{'models': SVC(class_weight='balanced', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>0.890961</td>\n",
       "      <td>{'models': SVC(class_weight='balanced', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0.890961</td>\n",
       "      <td>{'models': SVC(class_weight='balanced', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>0.889490</td>\n",
       "      <td>{'models': SVC(class_weight='balanced', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.889123</td>\n",
       "      <td>{'models': LogisticRegression(class_weight='ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.888862</td>\n",
       "      <td>{'models': LogisticRegression(class_weight='ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12</td>\n",
       "      <td>0.888312</td>\n",
       "      <td>{'models': SVC(class_weight='balanced', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0.886301</td>\n",
       "      <td>{'models': LogisticRegression(class_weight='ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>0.886151</td>\n",
       "      <td>{'models': LogisticRegression(class_weight='ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15</td>\n",
       "      <td>0.881511</td>\n",
       "      <td>{'models': XGBClassifier(base_score=None, boos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>16</td>\n",
       "      <td>0.881401</td>\n",
       "      <td>{'models': XGBClassifier(base_score=None, boos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>17</td>\n",
       "      <td>0.880117</td>\n",
       "      <td>{'models': XGBClassifier(base_score=None, boos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>0.816350</td>\n",
       "      <td>{'models': SVC(class_weight='balanced', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>0.816350</td>\n",
       "      <td>{'models': SVC(class_weight='balanced', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>0.816350</td>\n",
       "      <td>{'models': SVC(class_weight='balanced', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.816350</td>\n",
       "      <td>{'models': SVC(class_weight='balanced', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>0.816350</td>\n",
       "      <td>{'models': SVC(class_weight='balanced', random...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  mean_test_score  \\\n",
       "4                 1         0.891811   \n",
       "7                 2         0.891584   \n",
       "10                3         0.891361   \n",
       "17                4         0.890961   \n",
       "14                4         0.890961   \n",
       "5                 4         0.890961   \n",
       "11                4         0.890961   \n",
       "8                 4         0.890961   \n",
       "13                9         0.889490   \n",
       "0                10         0.889123   \n",
       "1                11         0.888862   \n",
       "16               12         0.888312   \n",
       "3                13         0.886301   \n",
       "2                14         0.886151   \n",
       "19               15         0.881511   \n",
       "21               16         0.881401   \n",
       "20               17         0.880117   \n",
       "6                18         0.816350   \n",
       "12               18         0.816350   \n",
       "15               18         0.816350   \n",
       "18               18         0.816350   \n",
       "9                18         0.816350   \n",
       "\n",
       "                                               params  \n",
       "4   {'models': SVC(class_weight='balanced', random...  \n",
       "7   {'models': SVC(class_weight='balanced', random...  \n",
       "10  {'models': SVC(class_weight='balanced', random...  \n",
       "17  {'models': SVC(class_weight='balanced', random...  \n",
       "14  {'models': SVC(class_weight='balanced', random...  \n",
       "5   {'models': SVC(class_weight='balanced', random...  \n",
       "11  {'models': SVC(class_weight='balanced', random...  \n",
       "8   {'models': SVC(class_weight='balanced', random...  \n",
       "13  {'models': SVC(class_weight='balanced', random...  \n",
       "0   {'models': LogisticRegression(class_weight='ba...  \n",
       "1   {'models': LogisticRegression(class_weight='ba...  \n",
       "16  {'models': SVC(class_weight='balanced', random...  \n",
       "3   {'models': LogisticRegression(class_weight='ba...  \n",
       "2   {'models': LogisticRegression(class_weight='ba...  \n",
       "19  {'models': XGBClassifier(base_score=None, boos...  \n",
       "21  {'models': XGBClassifier(base_score=None, boos...  \n",
       "20  {'models': XGBClassifier(base_score=None, boos...  \n",
       "6   {'models': SVC(class_weight='balanced', random...  \n",
       "12  {'models': SVC(class_weight='balanced', random...  \n",
       "15  {'models': SVC(class_weight='balanced', random...  \n",
       "18  {'models': SVC(class_weight='balanced', random...  \n",
       "9   {'models': SVC(class_weight='balanced', random...  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)[['rank_test_score', 'mean_test_score','params']].sort_values('rank_test_score')#.loc[3]['params']#.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_pred = grid_search.best_estimator_.predict(dembs_test[:16000])#[:X_train.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78985,)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 768)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dembs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000,)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.6818181818181818"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test[test_sample.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.5166340508806262\n",
    "#0.670076726342711"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93879037, 0.62949085])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(grid_pred, test_sample['toxic'].iloc[:16000],average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6294908529865549"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(grid_pred, test_sample['toxic'].iloc[:16000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m(grid_pred, test_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoxic\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(grid_pred, test_sample['toxic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res =pd.DataFrame({'a':grid_pred, 'b':test_sample['toxic']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res['a']!=res['b']]['b'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from phik.report import plot_correlation_matrix\n",
    "#from phik import phik_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "phik_overview = phik_matrix(df[['toxic','word_count']],verbose=False)\n",
    "\n",
    "plot_correlation_matrix(\n",
    "    phik_overview.values,\n",
    "    x_labels=phik_overview.columns,\n",
    "    y_labels=phik_overview.index,\n",
    "    vmin=0, vmax=1, color_map='Blues',\n",
    "    title=r'correlation $\\phi_K$',\n",
    "    fontsize_factor=1.5,\n",
    "    figsize=(18, 14)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text_lemm'], \n",
    "    df['toxic'], \n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=df['toxic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampler = RandomUnderSampler(random_state=RANDOM_STATE)\n",
    "X_resample, y_resample = sampler.fit_resample(pd.DataFrame(X_train), pd.DataFrame(y_train)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resample.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 406,
    "start_time": "2025-08-18T19:09:24.283Z"
   },
   {
    "duration": 976,
    "start_time": "2025-08-18T19:09:47.447Z"
   },
   {
    "duration": 13,
    "start_time": "2025-08-18T19:09:57.004Z"
   },
   {
    "duration": 34,
    "start_time": "2025-08-18T19:11:01.787Z"
   },
   {
    "duration": 7,
    "start_time": "2025-08-18T19:11:51.371Z"
   },
   {
    "duration": 71,
    "start_time": "2025-08-18T19:18:11.221Z"
   },
   {
    "duration": 7324,
    "start_time": "2025-08-18T19:18:31.752Z"
   },
   {
    "duration": 2366,
    "start_time": "2025-08-18T19:18:42.522Z"
   },
   {
    "duration": 638,
    "start_time": "2025-08-18T19:18:46.740Z"
   },
   {
    "duration": 52,
    "start_time": "2025-08-18T19:19:05.932Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T19:20:05.266Z"
   },
   {
    "duration": 2,
    "start_time": "2025-08-18T19:21:09.819Z"
   },
   {
    "duration": 9,
    "start_time": "2025-08-18T19:21:24.068Z"
   },
   {
    "duration": 23,
    "start_time": "2025-08-18T19:22:05.917Z"
   },
   {
    "duration": 9,
    "start_time": "2025-08-18T19:23:17.506Z"
   },
   {
    "duration": 2,
    "start_time": "2025-08-18T19:24:15.955Z"
   },
   {
    "duration": 99,
    "start_time": "2025-08-18T19:24:30.236Z"
   },
   {
    "duration": 17,
    "start_time": "2025-08-18T19:24:50.180Z"
   },
   {
    "duration": 18,
    "start_time": "2025-08-18T19:25:21.649Z"
   },
   {
    "duration": 17,
    "start_time": "2025-08-18T19:25:35.470Z"
   },
   {
    "duration": 54,
    "start_time": "2025-08-18T19:27:41.878Z"
   },
   {
    "duration": 7,
    "start_time": "2025-08-18T19:27:55.628Z"
   },
   {
    "duration": 9,
    "start_time": "2025-08-18T19:28:25.512Z"
   },
   {
    "duration": 7,
    "start_time": "2025-08-18T19:28:36.733Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-18T19:43:50.418Z"
   },
   {
    "duration": 76,
    "start_time": "2025-08-18T19:43:53.290Z"
   },
   {
    "duration": 44,
    "start_time": "2025-08-18T19:43:58.942Z"
   },
   {
    "duration": 9,
    "start_time": "2025-08-18T20:01:42.440Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T20:04:30.308Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:08:23.893Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-18T20:08:51.300Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:09:05.354Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:09:48.303Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-18T20:10:01.688Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-18T20:11:33.427Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T20:11:38.262Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:11:39.629Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T20:11:50.462Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-18T20:11:51.853Z"
   },
   {
    "duration": 4391,
    "start_time": "2025-08-18T20:12:50.783Z"
   },
   {
    "duration": 4355,
    "start_time": "2025-08-18T20:13:13.006Z"
   },
   {
    "duration": 4625,
    "start_time": "2025-08-18T20:13:32.152Z"
   },
   {
    "duration": 10,
    "start_time": "2025-08-18T20:17:06.253Z"
   },
   {
    "duration": 2,
    "start_time": "2025-08-18T20:30:29.649Z"
   },
   {
    "duration": 10,
    "start_time": "2025-08-18T20:30:37.731Z"
   },
   {
    "duration": 3208,
    "start_time": "2025-08-18T20:30:40.953Z"
   },
   {
    "duration": 208,
    "start_time": "2025-08-18T20:31:13.163Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T20:31:43.147Z"
   },
   {
    "duration": 25,
    "start_time": "2025-08-18T20:32:15.848Z"
   },
   {
    "duration": 18,
    "start_time": "2025-08-18T20:32:37.920Z"
   },
   {
    "duration": 18,
    "start_time": "2025-08-18T20:32:47.420Z"
   },
   {
    "duration": 18,
    "start_time": "2025-08-18T20:35:57.628Z"
   },
   {
    "duration": 17,
    "start_time": "2025-08-18T20:38:26.028Z"
   },
   {
    "duration": 84,
    "start_time": "2025-08-18T20:41:50.277Z"
   },
   {
    "duration": 500,
    "start_time": "2025-08-18T20:42:03.816Z"
   },
   {
    "duration": 30,
    "start_time": "2025-08-18T20:42:27.568Z"
   },
   {
    "duration": 19,
    "start_time": "2025-08-18T20:42:43.879Z"
   },
   {
    "duration": 19,
    "start_time": "2025-08-18T20:42:52.612Z"
   },
   {
    "duration": 11,
    "start_time": "2025-08-18T20:43:10.466Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:43:34.481Z"
   },
   {
    "duration": 19,
    "start_time": "2025-08-18T20:45:39.302Z"
   },
   {
    "duration": 9,
    "start_time": "2025-08-18T20:46:42.581Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:46:46.700Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:47:07.407Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:48:23.658Z"
   },
   {
    "duration": 14,
    "start_time": "2025-08-18T20:48:42.988Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T20:49:12.478Z"
   },
   {
    "duration": 9,
    "start_time": "2025-08-18T20:49:21.311Z"
   },
   {
    "duration": 82,
    "start_time": "2025-08-18T20:50:04.814Z"
   },
   {
    "duration": 11,
    "start_time": "2025-08-18T20:50:41.375Z"
   },
   {
    "duration": 72,
    "start_time": "2025-08-18T20:50:44.499Z"
   },
   {
    "duration": 18,
    "start_time": "2025-08-18T20:51:17.776Z"
   },
   {
    "duration": 31,
    "start_time": "2025-08-18T20:51:32.035Z"
   },
   {
    "duration": 33,
    "start_time": "2025-08-18T20:52:03.189Z"
   },
   {
    "duration": 70,
    "start_time": "2025-08-18T20:53:02.892Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T20:53:17.975Z"
   },
   {
    "duration": 10,
    "start_time": "2025-08-18T20:53:35.266Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T20:53:46.379Z"
   },
   {
    "duration": 69,
    "start_time": "2025-08-18T20:53:47.797Z"
   },
   {
    "duration": 302,
    "start_time": "2025-08-18T20:54:14.768Z"
   },
   {
    "duration": 375,
    "start_time": "2025-08-18T20:54:27.606Z"
   },
   {
    "duration": 70,
    "start_time": "2025-08-18T20:54:33.372Z"
   },
   {
    "duration": 7,
    "start_time": "2025-08-18T20:54:52.299Z"
   },
   {
    "duration": 1172,
    "start_time": "2025-08-18T20:55:36.234Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:55:47.977Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:55:54.214Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T20:56:35.643Z"
   },
   {
    "duration": 17,
    "start_time": "2025-08-18T20:56:51.987Z"
   },
   {
    "duration": 320,
    "start_time": "2025-08-18T20:59:09.313Z"
   },
   {
    "duration": 8087,
    "start_time": "2025-08-18T20:59:46.419Z"
   },
   {
    "duration": 488,
    "start_time": "2025-08-18T21:00:10.574Z"
   },
   {
    "duration": 2,
    "start_time": "2025-08-18T21:00:32.098Z"
   },
   {
    "duration": 495,
    "start_time": "2025-08-18T21:00:33.903Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T21:00:36.626Z"
   },
   {
    "duration": 12,
    "start_time": "2025-08-18T21:00:37.887Z"
   },
   {
    "duration": 30,
    "start_time": "2025-08-18T21:00:41.452Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T21:00:57.292Z"
   },
   {
    "duration": 24,
    "start_time": "2025-08-18T21:01:12.068Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T21:07:00.983Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-18T21:07:27.166Z"
   },
   {
    "duration": 2,
    "start_time": "2025-08-18T21:07:28.929Z"
   },
   {
    "duration": 769,
    "start_time": "2025-08-18T21:07:48.911Z"
   },
   {
    "duration": 84,
    "start_time": "2025-08-18T21:08:43.198Z"
   },
   {
    "duration": 67,
    "start_time": "2025-08-18T21:11:21.466Z"
   },
   {
    "duration": 13733,
    "start_time": "2025-08-18T21:12:07.873Z"
   },
   {
    "duration": 357052,
    "start_time": "2025-08-18T21:12:26.388Z"
   },
   {
    "duration": 2420,
    "start_time": "2025-08-18T21:18:38.380Z"
   },
   {
    "duration": 1036,
    "start_time": "2025-08-18T21:18:40.802Z"
   },
   {
    "duration": 2780,
    "start_time": "2025-08-18T21:18:41.839Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T21:18:44.621Z"
   },
   {
    "duration": 7,
    "start_time": "2025-08-18T21:18:44.626Z"
   },
   {
    "duration": 873,
    "start_time": "2025-08-18T21:18:44.635Z"
   },
   {
    "duration": 16,
    "start_time": "2025-08-18T21:18:45.510Z"
   },
   {
    "duration": 50,
    "start_time": "2025-08-18T21:18:45.527Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T21:18:45.579Z"
   },
   {
    "duration": 4422,
    "start_time": "2025-08-18T21:18:45.584Z"
   },
   {
    "duration": 6,
    "start_time": "2025-08-18T21:18:50.007Z"
   },
   {
    "duration": 11,
    "start_time": "2025-08-18T21:18:50.015Z"
   },
   {
    "duration": 651,
    "start_time": "2025-08-18T21:18:50.028Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T21:18:50.680Z"
   },
   {
    "duration": 8,
    "start_time": "2025-08-18T21:18:50.684Z"
   },
   {
    "duration": 38,
    "start_time": "2025-08-18T21:18:50.694Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-18T21:18:50.734Z"
   },
   {
    "duration": 7,
    "start_time": "2025-08-18T21:18:50.741Z"
   },
   {
    "duration": 97352,
    "start_time": "2025-08-18T21:18:50.749Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-18T21:20:28.102Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-18T21:20:28.104Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-18T21:20:28.105Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-18T21:20:28.106Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-18T21:20:28.107Z"
   },
   {
    "duration": 55,
    "start_time": "2025-08-19T05:57:12.644Z"
   },
   {
    "duration": 1364,
    "start_time": "2025-08-19T05:57:18.742Z"
   },
   {
    "duration": 9004,
    "start_time": "2025-08-19T05:57:22.652Z"
   },
   {
    "duration": 25,
    "start_time": "2025-08-19T05:57:31.660Z"
   },
   {
    "duration": 2845,
    "start_time": "2025-08-19T05:57:59.992Z"
   },
   {
    "duration": 1205,
    "start_time": "2025-08-19T05:58:02.840Z"
   },
   {
    "duration": 3666,
    "start_time": "2025-08-19T05:58:04.048Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-19T05:58:07.716Z"
   },
   {
    "duration": 53,
    "start_time": "2025-08-19T05:58:07.721Z"
   },
   {
    "duration": 1056,
    "start_time": "2025-08-19T05:58:07.776Z"
   },
   {
    "duration": 28,
    "start_time": "2025-08-19T05:58:08.834Z"
   },
   {
    "duration": 79,
    "start_time": "2025-08-19T05:58:08.864Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-19T05:58:08.945Z"
   },
   {
    "duration": 4967,
    "start_time": "2025-08-19T05:58:08.951Z"
   },
   {
    "duration": 8,
    "start_time": "2025-08-19T05:58:13.919Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-19T05:58:13.929Z"
   },
   {
    "duration": 771,
    "start_time": "2025-08-19T05:58:13.934Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-19T05:58:14.708Z"
   },
   {
    "duration": 22,
    "start_time": "2025-08-19T05:58:14.713Z"
   },
   {
    "duration": 23175,
    "start_time": "2025-08-19T05:58:14.737Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T05:58:37.915Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T05:58:37.916Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T05:58:37.917Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T05:58:37.919Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T05:58:37.921Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T05:58:37.922Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-19T06:00:31.236Z"
   },
   {
    "duration": 2924,
    "start_time": "2025-08-19T06:01:01.130Z"
   },
   {
    "duration": 1170,
    "start_time": "2025-08-19T06:01:04.058Z"
   },
   {
    "duration": 3433,
    "start_time": "2025-08-19T06:01:05.230Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-19T06:01:08.665Z"
   },
   {
    "duration": 802,
    "start_time": "2025-08-19T06:01:08.672Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-19T06:01:09.476Z"
   },
   {
    "duration": 1034,
    "start_time": "2025-08-19T06:01:09.481Z"
   },
   {
    "duration": 19,
    "start_time": "2025-08-19T06:01:10.517Z"
   },
   {
    "duration": 56,
    "start_time": "2025-08-19T06:01:10.538Z"
   },
   {
    "duration": 69,
    "start_time": "2025-08-19T06:01:10.595Z"
   },
   {
    "duration": 6,
    "start_time": "2025-08-19T06:01:10.666Z"
   },
   {
    "duration": 6,
    "start_time": "2025-08-19T06:01:10.674Z"
   },
   {
    "duration": 19,
    "start_time": "2025-08-19T06:01:10.682Z"
   },
   {
    "duration": 3056180,
    "start_time": "2025-08-19T06:01:10.704Z"
   },
   {
    "duration": 9,
    "start_time": "2025-08-19T06:52:06.886Z"
   },
   {
    "duration": 37,
    "start_time": "2025-08-19T06:52:06.898Z"
   },
   {
    "duration": 345,
    "start_time": "2025-08-19T06:52:06.937Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T06:52:07.284Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T06:52:07.286Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T06:52:07.287Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T06:52:07.289Z"
   },
   {
    "duration": 26,
    "start_time": "2025-08-19T06:54:01.622Z"
   },
   {
    "duration": 98,
    "start_time": "2025-08-19T06:54:07.568Z"
   },
   {
    "duration": 273,
    "start_time": "2025-08-19T06:56:24.310Z"
   },
   {
    "duration": 47,
    "start_time": "2025-08-19T06:56:29.808Z"
   },
   {
    "duration": 26,
    "start_time": "2025-08-19T06:56:54.409Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-19T07:00:03.035Z"
   },
   {
    "duration": 11,
    "start_time": "2025-08-19T07:00:07.705Z"
   },
   {
    "duration": 43,
    "start_time": "2025-08-19T07:01:09.198Z"
   },
   {
    "duration": 22,
    "start_time": "2025-08-19T07:01:17.084Z"
   },
   {
    "duration": 14,
    "start_time": "2025-08-19T07:01:20.949Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
