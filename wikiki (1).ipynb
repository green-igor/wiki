{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install imbalanced-learn -q\n",
    "#!pip install swifter - q\n",
    "\n",
    "#!pip install lightgbm\n",
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import notebook\n",
    "import re\n",
    "from time import time \n",
    "#import nltk\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from __future__ import unicode_literals, print_function\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TunedThresholdClassifierCV\n",
    "from sklearn.model_selection import FixedThresholdClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\LeeCo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spacy\n",
    "#from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "#from spacy.pipeline import Lemmatizer\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = transformers.BertTokenizer(\n",
    "#    vocab_file='datasets/ds_bert/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')#'distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x231ad55b4d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nlp = English()\n",
    "#nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='bert-large-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2002, 2743, 1012, 2002, 3062, 1012, 102]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('He ran. He fell.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[PAD]': 0, '[UNK]': 100, '[CLS]': 101, '[SEP]': 102, '[MASK]': 103}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.added_tokens_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, '[CLS]')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2002, 'he')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2743, 'ran')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1012, '.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2002, 'he')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3062, 'fell')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1012, '.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(13360, 'aaa')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(11057, '##aa')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(11057, '##aa')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(11057, '##aa')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(11057, '##aa')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1012, '.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1012, '.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1012, '.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(102, '[SEP]')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for enc in tokenizer.encode('He ran. He fell. Aaaaaaaaaaa...'):\n",
    "    display((enc,tokenizer.decode([f'{enc}'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5789947509765625e-05"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "#df['text'].apply(lambda x: len(str(x).split()))\n",
    "end = time()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://code.s3.yandex.net/datasets/toxic_comments.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    string = re.sub(r'[^a-z]', ' ', string, flags=re.IGNORECASE)\n",
    "    string = string.split()\n",
    "    string = ' '.join(string)\n",
    "    return string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].apply(lambda x:clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1323)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop_duplicates(subset='clean_text', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].str.lower().drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def sents(string):\n",
    "    doc = nlp(string)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['text'].apply(lambda x: x.count(' ') + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['sent_count'] = df['text'].apply(lambda x: len(sents(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['len'] = df['text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4167</th>\n",
       "      <td>ii CAN STILL POST WITH THIS COMPUTER...I SAID ...</td>\n",
       "      <td>1</td>\n",
       "      <td>ii can still post with this computer i said bl...</td>\n",
       "      <td>773</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6190</th>\n",
       "      <td>SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SE...</td>\n",
       "      <td>1</td>\n",
       "      <td>securityfuck homeland securityfuck homeland se...</td>\n",
       "      <td>455</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8685</th>\n",
       "      <td>BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALL...</td>\n",
       "      <td>1</td>\n",
       "      <td>balls balls balls balls balls balls balls ball...</td>\n",
       "      <td>834</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9651</th>\n",
       "      <td>FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHE...</td>\n",
       "      <td>1</td>\n",
       "      <td>fuck you you atheist cunt fuck you you atheist...</td>\n",
       "      <td>894</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10746</th>\n",
       "      <td>TOMMY2010 IS A NIGGER TOMMY2010 IS A NIGGER TO...</td>\n",
       "      <td>1</td>\n",
       "      <td>tommy is a nigger tommy is a nigger tommy is a...</td>\n",
       "      <td>909</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12869</th>\n",
       "      <td>I OWN THIS PAGE YOU FOOLS!! YOU SHOULD FEAR ME...</td>\n",
       "      <td>1</td>\n",
       "      <td>i own this page you fools you should fear me i...</td>\n",
       "      <td>965</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16612</th>\n",
       "      <td>'''Hi Wikipedia!!Hi Wikipedia!!Hi Wikipedia!!H...</td>\n",
       "      <td>0</td>\n",
       "      <td>hi wikipedia hi wikipedia hi wikipedia hi wiki...</td>\n",
       "      <td>358</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18151</th>\n",
       "      <td>Hey guys I love chicken rice=)Hey guys I love ...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey guys i love chicken rice hey guys i love c...</td>\n",
       "      <td>835</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22334</th>\n",
       "      <td>I fuck niggas! I fuck niggas! I fuck niggas! I...</td>\n",
       "      <td>1</td>\n",
       "      <td>i fuck niggas i fuck niggas i fuck niggas i fu...</td>\n",
       "      <td>1001</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25647</th>\n",
       "      <td>\"....would you prefer expressing my frustratio...</td>\n",
       "      <td>0</td>\n",
       "      <td>would you prefer expressing my frustration in ...</td>\n",
       "      <td>946</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  toxic  \\\n",
       "4167   ii CAN STILL POST WITH THIS COMPUTER...I SAID ...      1   \n",
       "6190   SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SE...      1   \n",
       "8685   BALLS BALLS BALLS BALLS BALLS BALLS BALLS BALL...      1   \n",
       "9651   FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHE...      1   \n",
       "10746  TOMMY2010 IS A NIGGER TOMMY2010 IS A NIGGER TO...      1   \n",
       "12869  I OWN THIS PAGE YOU FOOLS!! YOU SHOULD FEAR ME...      1   \n",
       "16612  '''Hi Wikipedia!!Hi Wikipedia!!Hi Wikipedia!!H...      0   \n",
       "18151  Hey guys I love chicken rice=)Hey guys I love ...      0   \n",
       "22334  I fuck niggas! I fuck niggas! I fuck niggas! I...      1   \n",
       "25647  \"....would you prefer expressing my frustratio...      0   \n",
       "\n",
       "                                              clean_text  word_count   len  \n",
       "4167   ii can still post with this computer i said bl...         773  5000  \n",
       "6190   securityfuck homeland securityfuck homeland se...         455  5000  \n",
       "8685   balls balls balls balls balls balls balls ball...         834  5000  \n",
       "9651   fuck you you atheist cunt fuck you you atheist...         894  5000  \n",
       "10746  tommy is a nigger tommy is a nigger tommy is a...         909  5000  \n",
       "12869  i own this page you fools you should fear me i...         965  5000  \n",
       "16612  hi wikipedia hi wikipedia hi wikipedia hi wiki...         358  5000  \n",
       "18151  hey guys i love chicken rice hey guys i love c...         835  5000  \n",
       "22334  i fuck niggas i fuck niggas i fuck niggas i fu...        1001  5000  \n",
       "25647  would you prefer expressing my frustration in ...         946  5000  "
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['len']==df['len'].max()].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\n\\n \"\"Disappointing Players for Charlton\"\" \\n\\nI added in a section on the April Fools prank in the Crest\\'s section, as well as splitting the directors of the boardroom into two sections, Charlton Athletic Ltd & CAFC PLC.\\n\\n\"'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][154485]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df['text'][112719]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   text        159292 non-null  object\n",
      " 1   toxic       159292 non-null  int64 \n",
      " 2   clean_text  159292 non-null  object\n",
      " 3   word_count  159292 non-null  int64 \n",
      " 4   len         159292 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['text_lower'] = df['mid_text'].str.lower()\n",
    "#df.drop_duplicates(subset='text_lower', inplace=True)\n",
    "#df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_plt(df_list, name, val_list, plt_xlim=1):\n",
    "\n",
    "    x_max = min([series.max() for series in df_list])* plt_xlim\n",
    "\n",
    "    fig, ax = plt.subplots(2,1,figsize=(10,8))\n",
    "    ax[0].boxplot([df for df in df_list], vert=False)\n",
    "\n",
    "    ax[0].set_yticklabels(val_list)\n",
    "    ax[0].set_xlabel(name)\n",
    "    ax[0].set_xlim([0, x_max])\n",
    "\n",
    "    ax[1].hist([df for df in df_list], histtype='stepfilled', bins=500)\n",
    "    ax[1].set_ylabel('частота')\n",
    "    ax[1].set_xlabel(name)\n",
    "    ax[1].set_xlim([0, x_max])\n",
    "\n",
    "    \n",
    "    plt.suptitle(f'Ящики с усами и гистограмма для признака \"{name}\"')\n",
    "    plt.legend(val_list);\n",
    "    #plt.xlim((0,x_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict = {'word_count' : 'количество слов',\n",
    " 'sent_count' : 'количество предложений',\n",
    " 'len' : 'количество символов'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for col in ['word_count', 'sent_count', 'len']:\n",
    "    \n",
    "    distribution_plt(\n",
    "        \n",
    "        [df[df['toxic']==1][col], df[df['toxic']==0][col]],\n",
    "        \n",
    "        name_dict[col],\n",
    "        \n",
    "        ['токсичные\\nкомментарии', 'не токсичные\\nкомментарии'],\n",
    "        \n",
    "        0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4704    do go fuck off bastard\\nDo Yyou Have a life?\\n...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'].str.contains('I ass. I ass.')]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logy(feats, target):\n",
    "    lr = LogisticRegression(random_state=RANDOM_STATE,max_iter=1000,class_weight='balanced')\n",
    "    lr.fit(feats, target)\n",
    "    scores = cross_val_score(lr, feats, target, cv=5, scoring='f1_macro')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4096*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = df.sample(n=6000, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    samp['text'],\n",
    "    samp['toxic'],\n",
    "    test_size = 0.5,\n",
    "    random_state = RANDOM_STATE,\n",
    "    stratify = samp['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000,), (3000,), (3000,), (3000,))"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(string):\n",
    "    \n",
    "    sents_ = sent_tokenize(string)\n",
    "\n",
    "    tokenized_sents = [tokenizer.encode(sent, add_special_tokens=True) for sent in sents_]\n",
    "\n",
    "    usents=[]\n",
    "    \n",
    "    for sent in tokenized_sents:\n",
    "        if sent not in usents:\n",
    "            usents.append(sent)\n",
    "    \n",
    "    if len(usents)>1:\n",
    "       result =  sum(usents, [])\n",
    "    elif len(usents)==1:\n",
    "        result = usents[0]\n",
    "    else:\n",
    "        result = tokenized_sents[0]\n",
    "        \n",
    "    \n",
    "    \n",
    "    return [101] + result[1:-1][:510] + [102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunker(df['text'][16612]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def chunker(string):\n",
    "    \n",
    "    sents_ = sents(string)\n",
    "    \n",
    "    tokenz = tokenizer(sents_, add_special_tokens=True, padding=True, return_tensors='np')\n",
    "\n",
    "\n",
    "    model = transformers.BertModel.from_pretrained('bert-large-uncased')#'distilbert-base-uncased')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "                    batch_embeddings = model(torch.LongTensor(tokenz['input_ids']), attention_mask=torch.LongTensor(tokenz['attention_mask']))\n",
    "    #transformers.from_pretrained(distilbert-base-uncased)\n",
    "    \n",
    "    #batch_embeddings[0][:,0,:]\n",
    "    \n",
    "    return np.mean(batch_embeddings[0][:,0,:].numpy(),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.06014431e-01, -6.21548295e-02, -1.01379892e-02, -1.68441549e-01,\n",
       "        4.32150885e-02, -1.96783051e-01,  9.86524299e-02,  4.27524507e-01,\n",
       "       -2.31145293e-01, -2.97342479e-01, -4.49013636e-02, -1.79771557e-01,\n",
       "       -1.97978646e-01,  4.04549897e-01,  3.10555249e-02,  3.12551588e-01,\n",
       "       -9.21233743e-02,  2.11014494e-01,  1.90578029e-01, -1.21308025e-02,\n",
       "       -9.72667113e-02, -1.98384970e-01, -1.23006245e-02,  9.30938348e-02,\n",
       "       -1.51105355e-02, -3.25137191e-03,  1.03774011e-01, -1.01887979e-01,\n",
       "       -1.19080646e-02,  8.76610875e-02,  6.72649816e-02,  1.24185801e-01,\n",
       "       -1.93346590e-01, -1.08881399e-01,  5.38776512e-04, -1.28543496e-01,\n",
       "        1.45829124e-02, -6.01367913e-02, -1.17812902e-02,  8.68727118e-02,\n",
       "       -1.45049170e-01,  1.06997609e-01,  7.22344443e-02,  3.60909812e-02,\n",
       "       -2.58618314e-02, -1.04638956e-01, -2.39289665e+00, -1.21881008e-01,\n",
       "       -1.28574058e-01, -2.63087422e-01,  8.48741904e-02, -2.38394793e-02,\n",
       "        5.67158405e-03,  5.07055461e-01,  2.79792398e-01,  2.30634660e-01,\n",
       "       -3.36259395e-01,  2.39858657e-01,  4.47460972e-02,  1.26108453e-02,\n",
       "        2.97596544e-01,  5.48406579e-02, -5.19959293e-02, -9.26457271e-02,\n",
       "       -5.30849658e-02,  1.80137396e-01, -4.33314070e-02,  1.39127031e-01,\n",
       "       -1.83271781e-01,  3.51416200e-01, -2.76320368e-01, -1.13600180e-01,\n",
       "        1.57741427e-01, -1.38576897e-02,  7.07884058e-02,  5.24663851e-02,\n",
       "        1.57390290e-03,  1.60423800e-01, -1.59547597e-01,  1.08406745e-01,\n",
       "        6.44779624e-03,  3.25696856e-01,  1.82359070e-01,  1.22669404e-02,\n",
       "        5.10765314e-02,  1.08622059e-01, -3.10523421e-01, -8.94567445e-02,\n",
       "        2.42849186e-01,  4.61093366e-01, -1.81424931e-01,  8.74395743e-02,\n",
       "        9.27385613e-02,  1.53355524e-01,  2.33885616e-01, -3.95007819e-01,\n",
       "        2.07253501e-01, -5.50869703e-02,  2.13179246e-01,  3.26218903e-01,\n",
       "        1.52212843e-01, -3.09127010e-02,  1.22053839e-01, -3.48384202e-01,\n",
       "       -6.63460046e-02, -1.89757735e-01, -6.25555515e-02, -5.36874235e-02,\n",
       "        1.14549384e-01, -2.30973434e+00,  2.18103930e-01,  2.28701934e-01,\n",
       "       -7.98964649e-02, -3.63578379e-01, -1.00279734e-01,  3.06164235e-01,\n",
       "        1.93781957e-01, -5.89403138e-02,  1.11999407e-01, -8.86519551e-02,\n",
       "       -1.09573960e-01,  3.82430166e-01, -9.83638838e-02, -1.44793183e-01,\n",
       "       -4.23700809e-02,  2.19626263e-01,  1.34073319e-02, -8.14143494e-02,\n",
       "       -6.67347386e-02,  1.93287134e-01,  1.21442340e-01,  3.17913949e-01,\n",
       "        2.30393577e-02, -5.09082153e-02, -4.19621877e-02,  1.35878488e-01,\n",
       "        9.06381458e-02, -5.13553284e-02, -9.24783498e-02, -1.31119629e-02,\n",
       "       -3.75447959e-01, -5.38695343e-02, -2.73513079e+00,  2.96307176e-01,\n",
       "        4.02303547e-01, -5.75558171e-02, -3.68750058e-02, -1.45392820e-01,\n",
       "        4.07404937e-02,  1.99069232e-01,  1.21861868e-01,  1.95277303e-01,\n",
       "       -8.49035475e-03,  1.91320311e-02, -2.52754599e-01, -4.08620313e-02,\n",
       "       -1.84121251e-01,  4.00154702e-02,  2.40521342e-01,  2.21171185e-01,\n",
       "        2.63481200e-01, -1.29939035e-01,  8.02817866e-02, -1.02120541e-01,\n",
       "        4.00663726e-02,  1.22723460e-01,  2.37377018e-01,  3.20180766e-02,\n",
       "        1.90349385e-01, -2.33750162e-03, -1.68522686e-01, -1.70720816e-01,\n",
       "        4.04171526e-01, -1.56695515e-01,  1.92288563e-01,  7.10648149e-02,\n",
       "        1.86246131e-02,  2.24272028e-01,  2.21622705e-01, -1.80160508e-01,\n",
       "       -1.26677334e-01,  3.51321042e-01,  5.30709699e-02,  1.82025924e-01,\n",
       "        2.16451548e-02, -3.91123965e-02,  1.38735771e-01, -2.15882063e-01,\n",
       "       -8.94178748e-02,  1.54736280e-01,  2.50156987e-02, -3.16460341e-01,\n",
       "        4.98844162e-02, -8.21284503e-02,  2.14758515e-01,  3.67597714e-02,\n",
       "       -6.45300820e-02, -3.21684599e-01,  6.86742067e-02,  1.71839520e-01,\n",
       "       -2.48521343e-01, -6.30773380e-02, -7.43537545e-02,  1.47397723e-02,\n",
       "       -6.89901933e-02,  3.48338699e+00,  9.81330276e-02,  3.66280833e-03,\n",
       "        1.88446045e-01,  1.76086619e-01, -6.89477846e-02, -7.71965279e-05,\n",
       "       -6.99845999e-02, -4.98795398e-02,  7.91893750e-02, -4.55569103e-02,\n",
       "        2.38862589e-01, -3.22435014e-02,  7.03497157e-02, -1.97127894e-01,\n",
       "        1.93027362e-01,  1.43818498e-01, -2.40325537e-02,  1.79250836e-01,\n",
       "       -1.59723729e-01,  1.39777377e-01,  1.22483291e-01,  2.30153084e-01,\n",
       "        1.11352734e-01, -1.15003216e+00,  6.12586774e-02,  4.85697798e-02,\n",
       "       -1.20978551e-02,  2.67621905e-01, -2.04490647e-01, -1.27320468e-01,\n",
       "        1.24651277e-02, -7.32906628e-03,  9.63952988e-02,  2.46642102e-02,\n",
       "       -7.87175745e-02,  2.04836264e-01,  1.85998037e-01,  2.56211072e-01,\n",
       "       -9.01716873e-02,  3.82750303e-01,  1.81152195e-01, -1.78628653e-01,\n",
       "        1.07318282e-01, -7.10444152e-02,  1.79698914e-01,  2.28565037e-02,\n",
       "        5.42505197e-02, -2.08404571e-01,  2.13411927e-01, -3.33121121e-02,\n",
       "        6.11029156e-02,  8.80756304e-02, -2.57131845e-01, -2.43462965e-01,\n",
       "       -2.75416583e-01, -3.13788955e-03, -8.13517720e-02,  9.64137539e-02,\n",
       "       -3.85317177e-01, -2.11828560e-01,  1.59638688e-01, -1.55874506e-01,\n",
       "        4.17950228e-02,  8.77491683e-02, -1.15629904e-01, -1.39785543e-01,\n",
       "       -3.48731428e-01, -3.43799210e+00,  4.82456610e-02,  8.34152848e-02,\n",
       "        1.83190510e-01,  2.09743738e-01, -6.54708818e-02,  1.35188445e-01,\n",
       "        8.42454284e-02,  1.81067988e-01, -3.28878671e-01,  3.63660872e-01,\n",
       "        1.78199783e-01, -7.07199723e-02,  3.45976114e-01, -3.63223135e-01,\n",
       "        2.02567011e-01,  7.65122399e-02, -2.11206824e-01, -9.66499820e-02,\n",
       "       -2.25259766e-01, -5.76847158e-02,  2.38568202e-01, -1.41369939e-01,\n",
       "        1.10970803e-01, -2.72924211e-02, -1.64050031e-02, -1.93283409e-01,\n",
       "       -3.35003793e-01,  3.39552909e-02,  3.75038385e-02, -7.25586712e-03,\n",
       "       -1.45798072e-01,  1.92345425e-01, -2.14441523e-01, -1.40164360e-01,\n",
       "       -2.95527506e+00,  1.97835341e-01, -1.74209312e-01, -1.20262124e-01,\n",
       "        1.15943775e-02, -6.77953809e-02,  2.85635799e-01, -1.46451741e-01,\n",
       "       -1.36844322e-01,  6.56650141e-02,  1.34005800e-01, -2.60913581e-01,\n",
       "        6.71002641e-02,  2.59965003e-01,  3.87705892e-01,  6.36840835e-02,\n",
       "        3.23694676e-01, -9.41925421e-02,  3.65583189e-02,  2.27522641e-01,\n",
       "        1.21085346e-01, -7.04121962e-02, -1.40045360e-01, -7.41525665e-02,\n",
       "        2.05373257e-01,  4.56971616e-01, -4.56754833e-01, -7.15736598e-02,\n",
       "       -1.95115879e-01, -2.33196214e-01,  6.42623976e-02, -1.77592888e-01,\n",
       "        7.88866729e-02, -1.03220508e-01, -2.47146845e-01, -1.76745936e-01,\n",
       "       -7.52643868e-02,  1.67994127e-01,  2.52500117e-01, -2.11288147e-02,\n",
       "       -1.79172367e-01,  6.46289408e-01,  7.36957863e-02,  5.67177869e-02,\n",
       "        3.87525350e-01,  1.22507207e-01,  2.77742837e-02, -8.89232531e-02,\n",
       "       -1.44869789e-01,  1.55098557e-01, -3.25131379e-02,  1.46331295e-01,\n",
       "        1.28457654e+00, -5.15097864e-02,  1.01751842e-01, -2.36724287e-01,\n",
       "        4.20506626e-01, -8.77359509e-02, -5.09457774e-02,  2.72011936e-01,\n",
       "        4.10243183e-01, -1.26138583e-01,  1.65621281e-01, -1.35207281e-01,\n",
       "       -2.09305733e-02, -3.03301722e-01,  1.09913155e-01, -3.30784321e-01,\n",
       "        7.64311552e-02,  2.06493773e-02, -7.67796636e-02,  2.85538107e-01,\n",
       "       -1.25891283e-01, -8.71195376e-01, -2.25240245e-01, -6.31498173e-02,\n",
       "       -8.65859538e-02, -5.74325910e-03, -6.83162138e-02,  1.03455938e-01,\n",
       "       -1.95641905e-01,  3.27063985e-02, -9.71331969e-02,  2.10862502e-01,\n",
       "       -2.55865723e-01, -8.25591758e-02, -3.62325236e-02,  2.19594106e-01,\n",
       "       -3.54362905e-01, -1.45483837e-01, -5.30719720e-02,  2.03267738e-01,\n",
       "        2.34624237e-01,  2.00088322e-02, -9.68668312e-02,  5.04806973e-02,\n",
       "        3.08542818e-01, -8.24694455e-01,  1.23663329e-01, -7.21863657e-02,\n",
       "        6.11365363e-02, -2.35913917e-01, -2.23676234e-01,  1.08419597e-01,\n",
       "       -1.28385559e-01, -1.97361261e-01, -1.67118043e-01,  3.10492337e-01,\n",
       "        6.54824898e-02,  1.60606191e-01,  2.21721623e-02,  4.69928607e-02,\n",
       "        7.63645843e-02, -6.39708862e-02,  8.68284643e-01, -4.58347797e-02,\n",
       "        3.81589308e-03,  2.61324137e-01,  3.38965431e-02,  1.62784621e-01,\n",
       "        3.07451278e-01,  3.59632149e-02, -1.33590803e-01, -5.57791702e-02,\n",
       "       -2.48280436e-01, -5.36201000e-02, -4.61074449e-02, -1.57761365e-01,\n",
       "       -2.43798941e-01,  5.99872246e-02,  9.92651507e-02,  8.73243809e-02,\n",
       "       -2.27808565e-01, -5.62910676e-01, -4.50398438e-02, -1.27792209e-01,\n",
       "       -6.49436042e-02,  4.69885506e-02,  2.47214645e-01,  9.28854793e-02,\n",
       "        4.27869797e-01,  1.74815699e-01, -1.34989873e-01,  3.86772633e-01,\n",
       "       -1.16261244e-01,  3.83603066e-01,  9.62855369e-02,  9.50468704e-02,\n",
       "       -1.48868516e-01,  2.61648059e-01,  6.74503371e-02, -1.24218032e-01,\n",
       "        7.56289810e-02, -2.06254214e-01,  1.62632704e-01, -1.11237997e-02,\n",
       "        1.51139498e-01,  3.18157747e-02, -4.46086898e-02, -1.34529928e-02,\n",
       "        6.14322051e-02,  6.88930824e-02, -1.26919651e+00,  2.37486750e-01,\n",
       "        1.93962559e-01,  1.56355873e-01,  2.81859878e-02, -1.52418658e-03,\n",
       "       -5.99192381e-02,  3.89807969e-01,  1.81729168e-01, -6.88933656e-02,\n",
       "       -1.85948491e-01, -1.38350740e-01,  6.10327758e-02, -1.41795203e-01,\n",
       "        4.03294861e-02,  4.72812429e-02,  5.07263802e-02, -1.24749169e-01,\n",
       "        6.22736178e-02,  2.62305550e-02, -6.11179657e-02,  2.47823998e-01,\n",
       "        1.08801626e-01, -1.50212497e-01,  2.92076007e-03, -1.60441607e-01,\n",
       "        7.27110282e-02,  2.49003053e-01,  2.16332883e-01,  4.17903438e-02,\n",
       "       -7.86126107e-02, -2.39371255e-01, -4.08146322e-01, -1.73215359e-01,\n",
       "        3.07829082e-01, -2.41441622e-01, -1.64343063e-02,  5.77734970e-02,\n",
       "        2.64814138e-01,  1.33992165e-01, -3.47988367e-01,  2.77442247e-01,\n",
       "        1.20531008e-01, -1.14007831e-01,  4.14096057e-01,  4.20343466e-02,\n",
       "       -2.44725779e-01,  1.26722023e-01, -6.45259991e-02, -1.56090781e-01,\n",
       "        1.99610041e-03, -1.15483440e-01, -1.11896947e-01, -8.03120956e-02,\n",
       "        2.25565024e-02,  2.35216916e-02, -7.21186250e-02,  1.33587107e-01,\n",
       "       -8.54622200e-02, -1.66194215e-01,  3.44541997e-01, -3.21146756e-01,\n",
       "       -5.28842844e-02,  2.56559461e-01, -1.68089479e-01, -6.36150897e-01,\n",
       "       -5.65659069e-02, -1.40699044e-01, -1.51987836e-01,  3.73450629e-02,\n",
       "        3.22991937e-01, -7.30689839e-02, -2.03426853e-01,  9.98981372e-02,\n",
       "       -1.98171452e-01,  4.88353632e-02,  5.39804287e-02,  1.10904150e-01,\n",
       "        1.89931482e-01, -5.59605658e-02,  4.06841263e-02, -3.98339987e-01,\n",
       "       -1.61020309e-01,  1.37295336e-01,  6.62162825e-02,  1.59881741e-01,\n",
       "       -1.94378048e-01,  5.44351339e-02,  4.36077379e-02, -4.55120541e-02,\n",
       "       -2.46416599e-01, -1.29067943e-01,  7.23807663e-02,  3.29134502e-02,\n",
       "        1.54765800e-01,  7.10035339e-02,  1.67841405e-01, -7.65544921e-02,\n",
       "        1.95686556e-02, -1.79225534e-01, -3.35062966e-02,  2.73850739e-01,\n",
       "        1.37608901e-01,  1.00047842e-01,  6.03499524e-02,  1.75256848e-01,\n",
       "        3.08023661e-01, -2.45878100e-02, -2.74542540e-01, -6.85269088e-02,\n",
       "        3.29783149e-02, -6.02576043e-03, -7.05866050e-03,  3.11838817e-02,\n",
       "        7.27449581e-02, -1.61969885e-01, -7.29018450e-02, -3.10134917e-01,\n",
       "        1.94683290e+00,  3.43016475e-01,  7.89956525e-02,  2.45732814e-02,\n",
       "        1.86203390e-01, -3.54393348e-02, -1.73661020e-02,  2.58680046e-01,\n",
       "       -1.97404385e-01,  1.57068849e-01, -1.67126149e-01,  9.46595222e-02,\n",
       "       -4.62543312e-03,  1.33536011e-01,  2.23610625e-01,  1.13740548e-01,\n",
       "        1.03074573e-01, -1.80436924e-01, -3.62506419e-01,  6.19614264e-03,\n",
       "       -4.62840885e-01,  2.99255043e-01,  1.04870833e-01, -5.54549620e-02,\n",
       "       -7.09501877e-02,  1.12656571e-01,  8.53163078e-02, -3.40016596e-02,\n",
       "        1.47291139e-01,  1.66225716e-01,  5.07197715e-02,  1.66328222e-01,\n",
       "        1.78033933e-01,  2.96272546e-01, -2.69883156e-01, -5.89269139e-02,\n",
       "        4.14251499e-02, -2.41370678e-01, -6.26671463e-02, -5.68670221e-02,\n",
       "        1.62498020e-02, -2.04324588e-01,  4.01796639e-01,  1.17181726e-01,\n",
       "        2.90498026e-02,  4.75289732e-01, -8.95007141e-03, -2.09848896e-01,\n",
       "        9.79803875e-02,  2.32657269e-01, -1.37748912e-01, -1.09387480e-01,\n",
       "       -2.44054675e-01,  1.73150688e-01, -2.79876709e-01, -1.15230158e-01,\n",
       "       -3.74513566e-02, -5.84573746e-02, -2.97106453e-03,  2.44640961e-01,\n",
       "       -9.98886153e-02,  2.12844625e-01,  2.42205113e-01,  2.36277431e-02,\n",
       "        1.30979672e-01,  1.92028787e-02, -2.26369426e-01,  1.16453074e-01,\n",
       "        1.31967098e-01, -1.44474253e-01,  7.50274211e-03,  2.78956443e-01,\n",
       "        2.08434448e-01,  2.17623740e-01,  8.96768123e-02,  1.05591200e-01,\n",
       "        2.85830319e-01,  4.88905348e-02, -1.67776361e-01, -2.50561738e+00,\n",
       "        1.34268403e-01,  8.37743841e-03,  2.33128980e-01, -2.94180810e-02,\n",
       "        2.93980449e-01,  1.38456538e-01, -1.40798315e-01, -4.00821343e-02,\n",
       "       -9.19724852e-02,  1.78405166e-01,  3.22341025e-01,  3.23861688e-01,\n",
       "        1.57328453e-02,  1.98619500e-01,  8.57883878e-03,  1.78506166e-01,\n",
       "       -4.98811342e-02,  2.38052811e-02, -6.21822700e-02, -1.21197499e-01,\n",
       "        1.13658540e-01,  6.24127202e-02, -2.09926710e-01, -2.96334833e-01,\n",
       "        2.27104321e-01, -2.05689698e-01, -6.23236299e-02,  2.39336446e-01,\n",
       "        1.20291241e-01, -7.27540031e-02,  3.39247882e-01, -1.87759295e-01,\n",
       "        4.84936824e-03,  1.50464743e-01, -1.87749982e-01, -8.75467211e-02,\n",
       "       -3.58164050e-02,  2.67349910e-02,  2.76149035e-01, -2.40575541e-02,\n",
       "        4.26591009e-01, -1.05265498e-01,  7.78924823e-02, -6.36846572e-02,\n",
       "       -5.93523383e-02,  3.81640196e-01, -1.70466110e-01,  2.95354128e-01,\n",
       "       -3.63797456e-01, -6.70665354e-02, -2.05915757e-02,  2.16739461e-01,\n",
       "       -4.83377352e-02,  2.39094049e-01,  9.27089006e-02,  1.38728067e-01,\n",
       "        1.11247301e-02,  3.66936736e-02, -3.23214293e-01, -8.33700746e-02,\n",
       "       -1.23747764e-02, -5.25843240e-02, -8.52999166e-02,  2.38371879e-01,\n",
       "       -1.18344605e-01, -3.31817091e-01,  1.33865457e-02, -5.93123548e-02,\n",
       "       -1.50510997e-01, -1.14384554e-01,  5.95993102e-02,  1.07390843e-01,\n",
       "        8.93013477e-02,  1.55560449e-01,  8.02759733e-03,  7.72352815e-02,\n",
       "        2.67867863e-01,  3.54645476e-02,  9.56735238e-02, -4.16551419e-02,\n",
       "       -2.31759742e-01, -1.19304331e-02, -7.33916163e-02,  8.74847546e-02,\n",
       "       -6.85829449e+00, -2.15253308e-01, -1.09078132e-01, -1.64633170e-01,\n",
       "       -9.73308831e-02, -1.11960277e-01,  8.08011834e-03, -1.25453576e-01,\n",
       "        1.13412179e-01, -1.99534968e-01,  1.52605891e-01, -1.10345282e-01,\n",
       "       -1.12282388e-01, -9.79045630e-02,  3.41917008e-01,  3.86829942e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunker(df['text'][4700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTokenizer(object):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        #tokenizer,\n",
    "        #text=[],\n",
    "        text,\n",
    "        batch_size=1):\n",
    "        \n",
    "        self.text = text\n",
    "        self.batch_size = batch_size\n",
    "        self.model_class ,self.pretrained_weights = (\n",
    "            transformers.BertModel, 'bert-base-uncased')\n",
    "\n",
    "        self.model = self.model_class.from_pretrained(self.pretrained_weights)\n",
    "\n",
    "    \n",
    "    def get(self):\n",
    "\n",
    "        \n",
    "        tokenized = self.text.swifter.apply(lambda x: chunker(x))\n",
    "        \n",
    "        max_len = 0\n",
    "        \n",
    "        for tok in tokenized.values:\n",
    "            if len(tok) > max_len:\n",
    "                max_len = len(tok)\n",
    "\n",
    "        padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "        attention_mask = np.where(padded != 0, 1, 0)\n",
    "        \n",
    "        batch_size = self.batch_size\n",
    "        \n",
    "        embeddings = []\n",
    "        \n",
    "        for i in notebook.tqdm(range(len(padded) // batch_size)):\n",
    "                batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "                attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    batch_embeddings = self.model(batch, attention_mask=attention_mask_batch)\n",
    "                \n",
    "                embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "    \n",
    "        features = np.concatenate(embeddings)\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1432"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(df['text'][16612]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunker(df['text'][6190]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa7a12c53834a029d4f170120e0b4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8fd6f8733742d889d6eb85c6ff2d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dembs_train = BertTokenizer(text=X_train, batch_size=30).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180f7f007b3c41178c1299190ca80cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564f724a467443efa6b00c380f68c3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial = BertTokenizer(text=X_train, batch_size=50).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83608914, 0.80592992, 0.80231409, 0.79755344, 0.82055295])"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logy(dembs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80789152, 0.80608067, 0.80544205, 0.79700029, 0.81400535])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logy(dembs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.80789152, 0.80608067, 0.80544205, 0.79700029, 0.81400535"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dembs_test = BertTokenizer(text=X_test, batch_size=30).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55718584, 0.55718584, 0.55718584, ..., 0.55718584, 4.87171159,\n",
       "       0.55718584], shape=(30000,))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "sample_weights = compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=y_train #provide your own target name\n",
    ")\n",
    "\n",
    "sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    0.897367\n",
       "1    0.102633\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_eval(y_true, y_pred,):\n",
    "    #y_true = dtrain.get_label()\n",
    "    #err = 1 - f1_score(grid_pred, y_test, average=None)[1]\n",
    "    err = f1_score(y_pred, y_true, average=None)[1]\n",
    "    return  err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_xgb(y_pred, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    err =1 - f1_score(y_true, y_pred, average=None)[1]\n",
    "\n",
    "    return 'err', err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "my_func = make_scorer(f1_eval, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    0.897367\n",
       "1    0.102633\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "debs_no_dups = pd.DataFrame(dembs_train).join(pd.DataFrame(y_train.reset_index()['toxic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "debs_no_dups.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054554</td>\n",
       "      <td>0.032030</td>\n",
       "      <td>0.120778</td>\n",
       "      <td>-0.114607</td>\n",
       "      <td>-0.075923</td>\n",
       "      <td>-0.136677</td>\n",
       "      <td>0.020189</td>\n",
       "      <td>0.225854</td>\n",
       "      <td>-0.135898</td>\n",
       "      <td>-0.171853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101006</td>\n",
       "      <td>0.080337</td>\n",
       "      <td>-0.064391</td>\n",
       "      <td>0.177604</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>-0.193309</td>\n",
       "      <td>-0.046049</td>\n",
       "      <td>0.192293</td>\n",
       "      <td>0.222578</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026916</td>\n",
       "      <td>0.070370</td>\n",
       "      <td>-0.041623</td>\n",
       "      <td>-0.070733</td>\n",
       "      <td>0.077861</td>\n",
       "      <td>-0.232926</td>\n",
       "      <td>0.148254</td>\n",
       "      <td>0.412093</td>\n",
       "      <td>-0.169133</td>\n",
       "      <td>-0.332854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193595</td>\n",
       "      <td>0.064336</td>\n",
       "      <td>0.031726</td>\n",
       "      <td>0.189356</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>-0.165502</td>\n",
       "      <td>-0.025272</td>\n",
       "      <td>0.250942</td>\n",
       "      <td>0.280510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.040808</td>\n",
       "      <td>-0.026892</td>\n",
       "      <td>0.116677</td>\n",
       "      <td>-0.078166</td>\n",
       "      <td>-0.035422</td>\n",
       "      <td>-0.195369</td>\n",
       "      <td>0.161824</td>\n",
       "      <td>0.360852</td>\n",
       "      <td>-0.162770</td>\n",
       "      <td>-0.091233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048423</td>\n",
       "      <td>-0.054734</td>\n",
       "      <td>-0.057439</td>\n",
       "      <td>0.073722</td>\n",
       "      <td>-0.020744</td>\n",
       "      <td>-0.099020</td>\n",
       "      <td>-0.099139</td>\n",
       "      <td>0.271790</td>\n",
       "      <td>0.353031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.051494</td>\n",
       "      <td>-0.118144</td>\n",
       "      <td>0.135466</td>\n",
       "      <td>-0.082494</td>\n",
       "      <td>-0.017335</td>\n",
       "      <td>-0.195243</td>\n",
       "      <td>-0.063485</td>\n",
       "      <td>0.258741</td>\n",
       "      <td>-0.119786</td>\n",
       "      <td>-0.242215</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112844</td>\n",
       "      <td>-0.016042</td>\n",
       "      <td>-0.090609</td>\n",
       "      <td>0.245084</td>\n",
       "      <td>-0.206943</td>\n",
       "      <td>-0.137903</td>\n",
       "      <td>-0.286003</td>\n",
       "      <td>0.384027</td>\n",
       "      <td>0.331157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.015131</td>\n",
       "      <td>0.042579</td>\n",
       "      <td>-0.012480</td>\n",
       "      <td>-0.056407</td>\n",
       "      <td>-0.093443</td>\n",
       "      <td>-0.059389</td>\n",
       "      <td>0.056314</td>\n",
       "      <td>0.219939</td>\n",
       "      <td>-0.263359</td>\n",
       "      <td>-0.179751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104669</td>\n",
       "      <td>-0.016733</td>\n",
       "      <td>-0.062705</td>\n",
       "      <td>0.171592</td>\n",
       "      <td>0.114356</td>\n",
       "      <td>-0.172997</td>\n",
       "      <td>-0.032023</td>\n",
       "      <td>0.278494</td>\n",
       "      <td>0.177390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0.044590</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>-0.040821</td>\n",
       "      <td>-0.078365</td>\n",
       "      <td>-0.194404</td>\n",
       "      <td>-0.255145</td>\n",
       "      <td>0.224017</td>\n",
       "      <td>0.357888</td>\n",
       "      <td>-0.242456</td>\n",
       "      <td>-0.024003</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086306</td>\n",
       "      <td>0.034925</td>\n",
       "      <td>-0.199785</td>\n",
       "      <td>0.083316</td>\n",
       "      <td>-0.010829</td>\n",
       "      <td>-0.052159</td>\n",
       "      <td>0.016477</td>\n",
       "      <td>0.397497</td>\n",
       "      <td>0.419192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>-0.355209</td>\n",
       "      <td>-0.020035</td>\n",
       "      <td>-0.012108</td>\n",
       "      <td>-0.138657</td>\n",
       "      <td>-0.177016</td>\n",
       "      <td>-0.136832</td>\n",
       "      <td>0.035712</td>\n",
       "      <td>0.388245</td>\n",
       "      <td>-0.168578</td>\n",
       "      <td>-0.179795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077247</td>\n",
       "      <td>-0.042935</td>\n",
       "      <td>0.049135</td>\n",
       "      <td>0.111670</td>\n",
       "      <td>-0.095760</td>\n",
       "      <td>-0.070035</td>\n",
       "      <td>-0.103592</td>\n",
       "      <td>0.297826</td>\n",
       "      <td>0.507109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>-0.107784</td>\n",
       "      <td>-0.094219</td>\n",
       "      <td>0.132195</td>\n",
       "      <td>-0.157644</td>\n",
       "      <td>0.070041</td>\n",
       "      <td>-0.296841</td>\n",
       "      <td>0.093094</td>\n",
       "      <td>0.513813</td>\n",
       "      <td>-0.140068</td>\n",
       "      <td>-0.159314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010522</td>\n",
       "      <td>0.058193</td>\n",
       "      <td>-0.069481</td>\n",
       "      <td>0.265057</td>\n",
       "      <td>0.080197</td>\n",
       "      <td>-0.401160</td>\n",
       "      <td>-0.257445</td>\n",
       "      <td>0.245340</td>\n",
       "      <td>0.447246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0.154565</td>\n",
       "      <td>-0.029695</td>\n",
       "      <td>0.086085</td>\n",
       "      <td>-0.100714</td>\n",
       "      <td>0.036096</td>\n",
       "      <td>-0.258932</td>\n",
       "      <td>0.090568</td>\n",
       "      <td>0.402844</td>\n",
       "      <td>-0.084287</td>\n",
       "      <td>-0.194110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118389</td>\n",
       "      <td>0.026744</td>\n",
       "      <td>-0.056654</td>\n",
       "      <td>0.186123</td>\n",
       "      <td>0.035641</td>\n",
       "      <td>-0.144441</td>\n",
       "      <td>0.006354</td>\n",
       "      <td>0.371069</td>\n",
       "      <td>0.255829</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>-0.085489</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>-0.083190</td>\n",
       "      <td>-0.171334</td>\n",
       "      <td>-0.141874</td>\n",
       "      <td>-0.176089</td>\n",
       "      <td>0.190935</td>\n",
       "      <td>0.373499</td>\n",
       "      <td>-0.354261</td>\n",
       "      <td>-0.195005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086636</td>\n",
       "      <td>0.059036</td>\n",
       "      <td>-0.181110</td>\n",
       "      <td>0.156665</td>\n",
       "      <td>0.046404</td>\n",
       "      <td>-0.121769</td>\n",
       "      <td>-0.124836</td>\n",
       "      <td>0.375916</td>\n",
       "      <td>0.406495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29984 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.054554  0.032030  0.120778 -0.114607 -0.075923 -0.136677  0.020189   \n",
       "1      0.026916  0.070370 -0.041623 -0.070733  0.077861 -0.232926  0.148254   \n",
       "2     -0.040808 -0.026892  0.116677 -0.078166 -0.035422 -0.195369  0.161824   \n",
       "3     -0.051494 -0.118144  0.135466 -0.082494 -0.017335 -0.195243 -0.063485   \n",
       "4     -0.015131  0.042579 -0.012480 -0.056407 -0.093443 -0.059389  0.056314   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "29995  0.044590  0.001134 -0.040821 -0.078365 -0.194404 -0.255145  0.224017   \n",
       "29996 -0.355209 -0.020035 -0.012108 -0.138657 -0.177016 -0.136832  0.035712   \n",
       "29997 -0.107784 -0.094219  0.132195 -0.157644  0.070041 -0.296841  0.093094   \n",
       "29998  0.154565 -0.029695  0.086085 -0.100714  0.036096 -0.258932  0.090568   \n",
       "29999 -0.085489  0.001964 -0.083190 -0.171334 -0.141874 -0.176089  0.190935   \n",
       "\n",
       "              7         8         9  ...       759       760       761  \\\n",
       "0      0.225854 -0.135898 -0.171853  ... -0.101006  0.080337 -0.064391   \n",
       "1      0.412093 -0.169133 -0.332854  ... -0.193595  0.064336  0.031726   \n",
       "2      0.360852 -0.162770 -0.091233  ... -0.048423 -0.054734 -0.057439   \n",
       "3      0.258741 -0.119786 -0.242215  ... -0.112844 -0.016042 -0.090609   \n",
       "4      0.219939 -0.263359 -0.179751  ... -0.104669 -0.016733 -0.062705   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "29995  0.357888 -0.242456 -0.024003  ... -0.086306  0.034925 -0.199785   \n",
       "29996  0.388245 -0.168578 -0.179795  ... -0.077247 -0.042935  0.049135   \n",
       "29997  0.513813 -0.140068 -0.159314  ...  0.010522  0.058193 -0.069481   \n",
       "29998  0.402844 -0.084287 -0.194110  ... -0.118389  0.026744 -0.056654   \n",
       "29999  0.373499 -0.354261 -0.195005  ...  0.086636  0.059036 -0.181110   \n",
       "\n",
       "            762       763       764       765       766       767  toxic  \n",
       "0      0.177604  0.002480 -0.193309 -0.046049  0.192293  0.222578      0  \n",
       "1      0.189356  0.086667 -0.165502 -0.025272  0.250942  0.280510      0  \n",
       "2      0.073722 -0.020744 -0.099020 -0.099139  0.271790  0.353031      0  \n",
       "3      0.245084 -0.206943 -0.137903 -0.286003  0.384027  0.331157      0  \n",
       "4      0.171592  0.114356 -0.172997 -0.032023  0.278494  0.177390      0  \n",
       "...         ...       ...       ...       ...       ...       ...    ...  \n",
       "29995  0.083316 -0.010829 -0.052159  0.016477  0.397497  0.419192      0  \n",
       "29996  0.111670 -0.095760 -0.070035 -0.103592  0.297826  0.507109      1  \n",
       "29997  0.265057  0.080197 -0.401160 -0.257445  0.245340  0.447246      0  \n",
       "29998  0.186123  0.035641 -0.144441  0.006354  0.371069  0.255829      1  \n",
       "29999  0.156665  0.046404 -0.121769 -0.124836  0.375916  0.406495      0  \n",
       "\n",
       "[29984 rows x 769 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debs_no_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "\n",
    "    {\n",
    "        'models': [LogisticRegression(\n",
    "            random_state=RANDOM_STATE, class_weight='balanced')],\n",
    "        'models__solver': ['newton-cg', 'liblinear'],\n",
    "        #'models__class_weight':,\n",
    "        #'models__C': [0.1, 1]#,\n",
    "        #'models__penalty': ['l1', 'l2']\n",
    "          \n",
    "    },\n",
    "\n",
    "#    {\n",
    "#        'models': [SVC(random_state=RANDOM_STATE, class_weight='balanced')],\n",
    "#        'models__degree': range(3,8),\n",
    "#        'models__kernel': ['poly','rbf','sigmoid']\n",
    "#    },\n",
    "    {\n",
    "        'models': [XGBClassifier(\n",
    "            random_state=RANDOM_STATE,\n",
    "            scale_pos_weight = 0.897367\n",
    "            \n",
    "            )],\n",
    "        'models__n_estimators':[500],\n",
    "        'models__max_depth':[7],\n",
    "        'models__learning_rate':[0.7,0.1],\n",
    "        'models__eval_metric': [f1_xgb]\n",
    "    }\n",
    "    #{\n",
    "    #    'models': [LGBMClassifier(random_state=RANDOM_STATE, class_weight='balanced')],\n",
    "    #    'models__n_estimators': [1000],\n",
    "    #    'models__learning_rate': [0.1, 0.01, 0.03, 0.05, 0.07]\n",
    "    #}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param_grid = [\n",
    "\n",
    "    {\n",
    "        'models': [LogisticRegression(\n",
    "            random_state=RANDOM_STATE, class_weight='balanced')],\n",
    "        'models__solver': ['newton-cg', 'liblinear'],\n",
    "        #'models__class_weight':,\n",
    "        'models__C': [0.1]#,\n",
    "        #'models__penalty': ['l1', 'l2']\n",
    "          \n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('models',[LogisticRegression(random_state=RANDOM_STATE,class_weight='balanced')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-10 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-10 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-10 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-10 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-10 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;models&#x27;,\n",
       "                                        [LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                            random_state=88)])]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;models&#x27;: [LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                        random_state=88)],\n",
       "                          &#x27;models__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;liblinear&#x27;]},\n",
       "                         {&#x27;models&#x27;: [XGBClassifier(base_score=None,\n",
       "                                                   booster=None, callbacks=None,\n",
       "                                                   colsample_bylevel=None,\n",
       "                                                   c...\n",
       "                                                   max_leaves=None,\n",
       "                                                   min_child_weight=None,\n",
       "                                                   missing=nan,\n",
       "                                                   monotone_constraints=None,\n",
       "                                                   multi_strategy=None,\n",
       "                                                   n_estimators=None,\n",
       "                                                   n_jobs=None,\n",
       "                                                   num_parallel_tree=None, ...)],\n",
       "                          &#x27;models__eval_metric&#x27;: [&lt;function f1_xgb at 0x00000231F6CB9B20&gt;],\n",
       "                          &#x27;models__learning_rate&#x27;: [0.7, 0.1],\n",
       "                          &#x27;models__max_depth&#x27;: [7],\n",
       "                          &#x27;models__n_estimators&#x27;: [500]}],\n",
       "             scoring=make_scorer(f1_eval, response_method=&#x27;predict&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;models&#x27;,\n",
       "                                        [LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                            random_state=88)])]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;models&#x27;: [LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                        random_state=88)],\n",
       "                          &#x27;models__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;liblinear&#x27;]},\n",
       "                         {&#x27;models&#x27;: [XGBClassifier(base_score=None,\n",
       "                                                   booster=None, callbacks=None,\n",
       "                                                   colsample_bylevel=None,\n",
       "                                                   c...\n",
       "                                                   max_leaves=None,\n",
       "                                                   min_child_weight=None,\n",
       "                                                   missing=nan,\n",
       "                                                   monotone_constraints=None,\n",
       "                                                   multi_strategy=None,\n",
       "                                                   n_estimators=None,\n",
       "                                                   n_jobs=None,\n",
       "                                                   num_parallel_tree=None, ...)],\n",
       "                          &#x27;models__eval_metric&#x27;: [&lt;function f1_xgb at 0x00000231F6CB9B20&gt;],\n",
       "                          &#x27;models__learning_rate&#x27;: [0.7, 0.1],\n",
       "                          &#x27;models__max_depth&#x27;: [7],\n",
       "                          &#x27;models__n_estimators&#x27;: [500]}],\n",
       "             scoring=make_scorer(f1_eval, response_method=&#x27;predict&#x27;))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;models&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None, device=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False,\n",
       "                               eval_metric=&lt;function f1_xgb at 0x00000231F6CB9B20&gt;,\n",
       "                               feature_types=None, feature_weights=None,\n",
       "                               gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.7,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=7, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=500, n_jobs=None,\n",
       "                               num_parallel_tree=None, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False,\n",
       "              eval_metric=&lt;function f1_xgb at 0x00000231F6CB9B20&gt;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.7, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('models',\n",
       "                                        [LogisticRegression(class_weight='balanced',\n",
       "                                                            random_state=88)])]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'models': [LogisticRegression(class_weight='balanced',\n",
       "                                                        random_state=88)],\n",
       "                          'models__solver': ['newton-cg', 'liblinear']},\n",
       "                         {'models': [XGBClassifier(base_score=None,\n",
       "                                                   booster=None, callbacks=None,\n",
       "                                                   colsample_bylevel=None,\n",
       "                                                   c...\n",
       "                                                   max_leaves=None,\n",
       "                                                   min_child_weight=None,\n",
       "                                                   missing=nan,\n",
       "                                                   monotone_constraints=None,\n",
       "                                                   multi_strategy=None,\n",
       "                                                   n_estimators=None,\n",
       "                                                   n_jobs=None,\n",
       "                                                   num_parallel_tree=None, ...)],\n",
       "                          'models__eval_metric': [<function f1_xgb at 0x00000231F6CB9B20>],\n",
       "                          'models__learning_rate': [0.7, 0.1],\n",
       "                          'models__max_depth': [7],\n",
       "                          'models__n_estimators': [500]}],\n",
       "             scoring=make_scorer(f1_eval, response_method='predict'))"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    pipe, \n",
    "    param_grid, \n",
    "    cv=5,\n",
    "    scoring=my_func,\n",
    "    #scoring='f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(debs_no_dups.drop(['toxic'], axis=1), debs_no_dups['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.691408</td>\n",
       "      <td>{'models': XGBClassifier(base_score=None, boos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.690464</td>\n",
       "      <td>{'models': XGBClassifier(base_score=None, boos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.664492</td>\n",
       "      <td>{'models': LogisticRegression(class_weight='ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.663929</td>\n",
       "      <td>{'models': LogisticRegression(class_weight='ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score  \\\n",
       "2                1         0.691408   \n",
       "3                2         0.690464   \n",
       "0                3         0.664492   \n",
       "1                4         0.663929   \n",
       "\n",
       "                                              params  \n",
       "2  {'models': XGBClassifier(base_score=None, boos...  \n",
       "3  {'models': XGBClassifier(base_score=None, boos...  \n",
       "0  {'models': LogisticRegression(class_weight='ba...  \n",
       "1  {'models': LogisticRegression(class_weight='ba...  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)[['rank_test_score', 'mean_test_score','params']].sort_values('rank_test_score')#.iloc[1]['params']#.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_pred = grid_search.best_estimator_.predict(dembs_test)#[:X_train.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probs = pd.DataFrame(grid_search.best_estimator_.predict_proba(dembs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96984336, 0.69207773])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(grid_pred, y_test,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dembs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97     27727\n",
      "           1       0.60      0.81      0.69      2273\n",
      "\n",
      "    accuracy                           0.95     30000\n",
      "   macro avg       0.79      0.89      0.83     30000\n",
      "weighted avg       0.96      0.95      0.95     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(grid_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_tuned = TunedThresholdClassifierCV(\n",
    "    grid_search.best_estimator_, scoring=my_func,\n",
    ").fit(dembs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_preds = classifier_tuned.predict(dembs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7059925093632958"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ct_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.05050505)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_tuned.best_threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1_score(ct_preds, y_test, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96847788, 0.71155473])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_other_threshold = FixedThresholdClassifier(\n",
    "    grid_search.best_estimator_, threshold=0.15, response_method=\"predict_proba\"\n",
    ").fit(dembs_train, y_train)\n",
    "f1_score(y_test, classifier_other_threshold.predict(dembs_test),average=None)#82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(16)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dembs_train).duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7115547284723397"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, classifier_other_threshold.predict(dembs_test))#82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_preds_adj = classifier_tuned.predict(dembs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(cl_preds_adj,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res =pd.DataFrame({'a':grid_pred, 'b':test_sample['toxic']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(probs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'proba':list(probs[1])},\n",
    "              {'predicted':grid_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probs_res = pd.DataFrame(zip(y_test,probs[1],grid_pred),columns=['toxic', 'proba', 'pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probs_res[(probs_res['toxic']!=probs_res['pred']&(probs_res['toxic']==1))]['proba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[1961]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.apply(lambda x: len(x)).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[X_train.apply(lambda x: len(x))>2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.index.isin(res[res['a']!=res['b']].index))&(df['toxic']==1)]['text'].apply(lambda x: tokenizer.decode(chunker(x)))#.sample()\n",
    "\n",
    "\n",
    "\n",
    "#['b'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(chunker(df.loc[128933]['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[128933]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from phik.report import plot_correlation_matrix\n",
    "#from phik import phik_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "phik_overview = phik_matrix(df[['toxic','word_count']],verbose=False)\n",
    "\n",
    "plot_correlation_matrix(\n",
    "    phik_overview.values,\n",
    "    x_labels=phik_overview.columns,\n",
    "    y_labels=phik_overview.index,\n",
    "    vmin=0, vmax=1, color_map='Blues',\n",
    "    title=r'correlation $\\phi_K$',\n",
    "    fontsize_factor=1.5,\n",
    "    figsize=(18, 14)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text_lemm'], \n",
    "    df['toxic'], \n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=df['toxic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampler = RandomUnderSampler(random_state=RANDOM_STATE)\n",
    "X_resample, y_resample = sampler.fit_resample(pd.DataFrame(X_train), pd.DataFrame(y_train)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resample.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 406,
    "start_time": "2025-08-18T19:09:24.283Z"
   },
   {
    "duration": 976,
    "start_time": "2025-08-18T19:09:47.447Z"
   },
   {
    "duration": 13,
    "start_time": "2025-08-18T19:09:57.004Z"
   },
   {
    "duration": 34,
    "start_time": "2025-08-18T19:11:01.787Z"
   },
   {
    "duration": 7,
    "start_time": "2025-08-18T19:11:51.371Z"
   },
   {
    "duration": 71,
    "start_time": "2025-08-18T19:18:11.221Z"
   },
   {
    "duration": 7324,
    "start_time": "2025-08-18T19:18:31.752Z"
   },
   {
    "duration": 2366,
    "start_time": "2025-08-18T19:18:42.522Z"
   },
   {
    "duration": 638,
    "start_time": "2025-08-18T19:18:46.740Z"
   },
   {
    "duration": 52,
    "start_time": "2025-08-18T19:19:05.932Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T19:20:05.266Z"
   },
   {
    "duration": 2,
    "start_time": "2025-08-18T19:21:09.819Z"
   },
   {
    "duration": 9,
    "start_time": "2025-08-18T19:21:24.068Z"
   },
   {
    "duration": 23,
    "start_time": "2025-08-18T19:22:05.917Z"
   },
   {
    "duration": 9,
    "start_time": "2025-08-18T19:23:17.506Z"
   },
   {
    "duration": 2,
    "start_time": "2025-08-18T19:24:15.955Z"
   },
   {
    "duration": 99,
    "start_time": "2025-08-18T19:24:30.236Z"
   },
   {
    "duration": 17,
    "start_time": "2025-08-18T19:24:50.180Z"
   },
   {
    "duration": 18,
    "start_time": "2025-08-18T19:25:21.649Z"
   },
   {
    "duration": 17,
    "start_time": "2025-08-18T19:25:35.470Z"
   },
   {
    "duration": 54,
    "start_time": "2025-08-18T19:27:41.878Z"
   },
   {
    "duration": 7,
    "start_time": "2025-08-18T19:27:55.628Z"
   },
   {
    "duration": 9,
    "start_time": "2025-08-18T19:28:25.512Z"
   },
   {
    "duration": 7,
    "start_time": "2025-08-18T19:28:36.733Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-18T19:43:50.418Z"
   },
   {
    "duration": 76,
    "start_time": "2025-08-18T19:43:53.290Z"
   },
   {
    "duration": 44,
    "start_time": "2025-08-18T19:43:58.942Z"
   },
   {
    "duration": 9,
    "start_time": "2025-08-18T20:01:42.440Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T20:04:30.308Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:08:23.893Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-18T20:08:51.300Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:09:05.354Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:09:48.303Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-18T20:10:01.688Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-18T20:11:33.427Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T20:11:38.262Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:11:39.629Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T20:11:50.462Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-18T20:11:51.853Z"
   },
   {
    "duration": 4391,
    "start_time": "2025-08-18T20:12:50.783Z"
   },
   {
    "duration": 4355,
    "start_time": "2025-08-18T20:13:13.006Z"
   },
   {
    "duration": 4625,
    "start_time": "2025-08-18T20:13:32.152Z"
   },
   {
    "duration": 10,
    "start_time": "2025-08-18T20:17:06.253Z"
   },
   {
    "duration": 2,
    "start_time": "2025-08-18T20:30:29.649Z"
   },
   {
    "duration": 10,
    "start_time": "2025-08-18T20:30:37.731Z"
   },
   {
    "duration": 3208,
    "start_time": "2025-08-18T20:30:40.953Z"
   },
   {
    "duration": 208,
    "start_time": "2025-08-18T20:31:13.163Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T20:31:43.147Z"
   },
   {
    "duration": 25,
    "start_time": "2025-08-18T20:32:15.848Z"
   },
   {
    "duration": 18,
    "start_time": "2025-08-18T20:32:37.920Z"
   },
   {
    "duration": 18,
    "start_time": "2025-08-18T20:32:47.420Z"
   },
   {
    "duration": 18,
    "start_time": "2025-08-18T20:35:57.628Z"
   },
   {
    "duration": 17,
    "start_time": "2025-08-18T20:38:26.028Z"
   },
   {
    "duration": 84,
    "start_time": "2025-08-18T20:41:50.277Z"
   },
   {
    "duration": 500,
    "start_time": "2025-08-18T20:42:03.816Z"
   },
   {
    "duration": 30,
    "start_time": "2025-08-18T20:42:27.568Z"
   },
   {
    "duration": 19,
    "start_time": "2025-08-18T20:42:43.879Z"
   },
   {
    "duration": 19,
    "start_time": "2025-08-18T20:42:52.612Z"
   },
   {
    "duration": 11,
    "start_time": "2025-08-18T20:43:10.466Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:43:34.481Z"
   },
   {
    "duration": 19,
    "start_time": "2025-08-18T20:45:39.302Z"
   },
   {
    "duration": 9,
    "start_time": "2025-08-18T20:46:42.581Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:46:46.700Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:47:07.407Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:48:23.658Z"
   },
   {
    "duration": 14,
    "start_time": "2025-08-18T20:48:42.988Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T20:49:12.478Z"
   },
   {
    "duration": 9,
    "start_time": "2025-08-18T20:49:21.311Z"
   },
   {
    "duration": 82,
    "start_time": "2025-08-18T20:50:04.814Z"
   },
   {
    "duration": 11,
    "start_time": "2025-08-18T20:50:41.375Z"
   },
   {
    "duration": 72,
    "start_time": "2025-08-18T20:50:44.499Z"
   },
   {
    "duration": 18,
    "start_time": "2025-08-18T20:51:17.776Z"
   },
   {
    "duration": 31,
    "start_time": "2025-08-18T20:51:32.035Z"
   },
   {
    "duration": 33,
    "start_time": "2025-08-18T20:52:03.189Z"
   },
   {
    "duration": 70,
    "start_time": "2025-08-18T20:53:02.892Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T20:53:17.975Z"
   },
   {
    "duration": 10,
    "start_time": "2025-08-18T20:53:35.266Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T20:53:46.379Z"
   },
   {
    "duration": 69,
    "start_time": "2025-08-18T20:53:47.797Z"
   },
   {
    "duration": 302,
    "start_time": "2025-08-18T20:54:14.768Z"
   },
   {
    "duration": 375,
    "start_time": "2025-08-18T20:54:27.606Z"
   },
   {
    "duration": 70,
    "start_time": "2025-08-18T20:54:33.372Z"
   },
   {
    "duration": 7,
    "start_time": "2025-08-18T20:54:52.299Z"
   },
   {
    "duration": 1172,
    "start_time": "2025-08-18T20:55:36.234Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:55:47.977Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-18T20:55:54.214Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T20:56:35.643Z"
   },
   {
    "duration": 17,
    "start_time": "2025-08-18T20:56:51.987Z"
   },
   {
    "duration": 320,
    "start_time": "2025-08-18T20:59:09.313Z"
   },
   {
    "duration": 8087,
    "start_time": "2025-08-18T20:59:46.419Z"
   },
   {
    "duration": 488,
    "start_time": "2025-08-18T21:00:10.574Z"
   },
   {
    "duration": 2,
    "start_time": "2025-08-18T21:00:32.098Z"
   },
   {
    "duration": 495,
    "start_time": "2025-08-18T21:00:33.903Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T21:00:36.626Z"
   },
   {
    "duration": 12,
    "start_time": "2025-08-18T21:00:37.887Z"
   },
   {
    "duration": 30,
    "start_time": "2025-08-18T21:00:41.452Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T21:00:57.292Z"
   },
   {
    "duration": 24,
    "start_time": "2025-08-18T21:01:12.068Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T21:07:00.983Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-18T21:07:27.166Z"
   },
   {
    "duration": 2,
    "start_time": "2025-08-18T21:07:28.929Z"
   },
   {
    "duration": 769,
    "start_time": "2025-08-18T21:07:48.911Z"
   },
   {
    "duration": 84,
    "start_time": "2025-08-18T21:08:43.198Z"
   },
   {
    "duration": 67,
    "start_time": "2025-08-18T21:11:21.466Z"
   },
   {
    "duration": 13733,
    "start_time": "2025-08-18T21:12:07.873Z"
   },
   {
    "duration": 357052,
    "start_time": "2025-08-18T21:12:26.388Z"
   },
   {
    "duration": 2420,
    "start_time": "2025-08-18T21:18:38.380Z"
   },
   {
    "duration": 1036,
    "start_time": "2025-08-18T21:18:40.802Z"
   },
   {
    "duration": 2780,
    "start_time": "2025-08-18T21:18:41.839Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T21:18:44.621Z"
   },
   {
    "duration": 7,
    "start_time": "2025-08-18T21:18:44.626Z"
   },
   {
    "duration": 873,
    "start_time": "2025-08-18T21:18:44.635Z"
   },
   {
    "duration": 16,
    "start_time": "2025-08-18T21:18:45.510Z"
   },
   {
    "duration": 50,
    "start_time": "2025-08-18T21:18:45.527Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T21:18:45.579Z"
   },
   {
    "duration": 4422,
    "start_time": "2025-08-18T21:18:45.584Z"
   },
   {
    "duration": 6,
    "start_time": "2025-08-18T21:18:50.007Z"
   },
   {
    "duration": 11,
    "start_time": "2025-08-18T21:18:50.015Z"
   },
   {
    "duration": 651,
    "start_time": "2025-08-18T21:18:50.028Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-18T21:18:50.680Z"
   },
   {
    "duration": 8,
    "start_time": "2025-08-18T21:18:50.684Z"
   },
   {
    "duration": 38,
    "start_time": "2025-08-18T21:18:50.694Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-18T21:18:50.734Z"
   },
   {
    "duration": 7,
    "start_time": "2025-08-18T21:18:50.741Z"
   },
   {
    "duration": 97352,
    "start_time": "2025-08-18T21:18:50.749Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-18T21:20:28.102Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-18T21:20:28.104Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-18T21:20:28.105Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-18T21:20:28.106Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-18T21:20:28.107Z"
   },
   {
    "duration": 55,
    "start_time": "2025-08-19T05:57:12.644Z"
   },
   {
    "duration": 1364,
    "start_time": "2025-08-19T05:57:18.742Z"
   },
   {
    "duration": 9004,
    "start_time": "2025-08-19T05:57:22.652Z"
   },
   {
    "duration": 25,
    "start_time": "2025-08-19T05:57:31.660Z"
   },
   {
    "duration": 2845,
    "start_time": "2025-08-19T05:57:59.992Z"
   },
   {
    "duration": 1205,
    "start_time": "2025-08-19T05:58:02.840Z"
   },
   {
    "duration": 3666,
    "start_time": "2025-08-19T05:58:04.048Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-19T05:58:07.716Z"
   },
   {
    "duration": 53,
    "start_time": "2025-08-19T05:58:07.721Z"
   },
   {
    "duration": 1056,
    "start_time": "2025-08-19T05:58:07.776Z"
   },
   {
    "duration": 28,
    "start_time": "2025-08-19T05:58:08.834Z"
   },
   {
    "duration": 79,
    "start_time": "2025-08-19T05:58:08.864Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-19T05:58:08.945Z"
   },
   {
    "duration": 4967,
    "start_time": "2025-08-19T05:58:08.951Z"
   },
   {
    "duration": 8,
    "start_time": "2025-08-19T05:58:13.919Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-19T05:58:13.929Z"
   },
   {
    "duration": 771,
    "start_time": "2025-08-19T05:58:13.934Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-19T05:58:14.708Z"
   },
   {
    "duration": 22,
    "start_time": "2025-08-19T05:58:14.713Z"
   },
   {
    "duration": 23175,
    "start_time": "2025-08-19T05:58:14.737Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T05:58:37.915Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T05:58:37.916Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T05:58:37.917Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T05:58:37.919Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T05:58:37.921Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T05:58:37.922Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-19T06:00:31.236Z"
   },
   {
    "duration": 2924,
    "start_time": "2025-08-19T06:01:01.130Z"
   },
   {
    "duration": 1170,
    "start_time": "2025-08-19T06:01:04.058Z"
   },
   {
    "duration": 3433,
    "start_time": "2025-08-19T06:01:05.230Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-19T06:01:08.665Z"
   },
   {
    "duration": 802,
    "start_time": "2025-08-19T06:01:08.672Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-19T06:01:09.476Z"
   },
   {
    "duration": 1034,
    "start_time": "2025-08-19T06:01:09.481Z"
   },
   {
    "duration": 19,
    "start_time": "2025-08-19T06:01:10.517Z"
   },
   {
    "duration": 56,
    "start_time": "2025-08-19T06:01:10.538Z"
   },
   {
    "duration": 69,
    "start_time": "2025-08-19T06:01:10.595Z"
   },
   {
    "duration": 6,
    "start_time": "2025-08-19T06:01:10.666Z"
   },
   {
    "duration": 6,
    "start_time": "2025-08-19T06:01:10.674Z"
   },
   {
    "duration": 19,
    "start_time": "2025-08-19T06:01:10.682Z"
   },
   {
    "duration": 3056180,
    "start_time": "2025-08-19T06:01:10.704Z"
   },
   {
    "duration": 9,
    "start_time": "2025-08-19T06:52:06.886Z"
   },
   {
    "duration": 37,
    "start_time": "2025-08-19T06:52:06.898Z"
   },
   {
    "duration": 345,
    "start_time": "2025-08-19T06:52:06.937Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T06:52:07.284Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T06:52:07.286Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T06:52:07.287Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-19T06:52:07.289Z"
   },
   {
    "duration": 26,
    "start_time": "2025-08-19T06:54:01.622Z"
   },
   {
    "duration": 98,
    "start_time": "2025-08-19T06:54:07.568Z"
   },
   {
    "duration": 273,
    "start_time": "2025-08-19T06:56:24.310Z"
   },
   {
    "duration": 47,
    "start_time": "2025-08-19T06:56:29.808Z"
   },
   {
    "duration": 26,
    "start_time": "2025-08-19T06:56:54.409Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-19T07:00:03.035Z"
   },
   {
    "duration": 11,
    "start_time": "2025-08-19T07:00:07.705Z"
   },
   {
    "duration": 43,
    "start_time": "2025-08-19T07:01:09.198Z"
   },
   {
    "duration": 22,
    "start_time": "2025-08-19T07:01:17.084Z"
   },
   {
    "duration": 14,
    "start_time": "2025-08-19T07:01:20.949Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
